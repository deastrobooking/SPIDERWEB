{"$message_type":"diagnostic","message":"unresolved import `rand::distributions::StandardNormal`","code":{"code":"E0432","explanation":"An import was unresolved.\n\nErroneous code example:\n\n```compile_fail,E0432\nuse something::Foo; // error: unresolved import `something::Foo`.\n```\n\nIn Rust 2015, paths in `use` statements are relative to the crate root. To\nimport items relative to the current and parent modules, use the `self::` and\n`super::` prefixes, respectively.\n\nIn Rust 2018 or later, paths in `use` statements are relative to the current\nmodule unless they begin with the name of a crate or a literal `crate::`, in\nwhich case they start from the crate root. As in Rust 2015 code, the `self::`\nand `super::` prefixes refer to the current and parent modules respectively.\n\nAlso verify that you didn't misspell the import name and that the import exists\nin the module from where you tried to import it. Example:\n\n```\nuse self::something::Foo; // Ok.\n\nmod something {\n    pub struct Foo;\n}\n# fn main() {}\n```\n\nIf you tried to use a module from an external crate and are using Rust 2015,\nyou may have missed the `extern crate` declaration (which is usually placed in\nthe crate root):\n\n```edition2015\nextern crate core; // Required to use the `core` crate in Rust 2015.\n\nuse core::any;\n# fn main() {}\n```\n\nSince Rust 2018 the `extern crate` declaration is not required and\nyou can instead just `use` it:\n\n```edition2018\nuse core::any; // No extern crate required in Rust 2018.\n# fn main() {}\n```\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":369,"byte_end":383,"line_start":9,"line_end":9,"column_start":50,"column_end":64,"is_primary":true,"text":[{"text":"use rand::distributions::{Distribution, Uniform, StandardNormal};","highlight_start":50,"highlight_end":64}],"label":"no `StandardNormal` in `distributions`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"consider importing one of these structs instead:\nndarray_rand::rand_distr::StandardNormal\nrand_distr::StandardNormal","code":null,"level":"help","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0432]\u001b[0m\u001b[0m\u001b[1m: unresolved import `rand::distributions::StandardNormal`\u001b[0m\n\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:9:50\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m9\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse rand::distributions::{Distribution, Uniform, StandardNormal};\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mno `StandardNormal` in `distributions`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mhelp\u001b[0m\u001b[0m: consider importing one of these structs instead:\u001b[0m\n\u001b[0m          ndarray_rand::rand_distr::StandardNormal\u001b[0m\n\u001b[0m          rand_distr::StandardNormal\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unresolved import `ndarray_linalg::Dot`","code":{"code":"E0432","explanation":"An import was unresolved.\n\nErroneous code example:\n\n```compile_fail,E0432\nuse something::Foo; // error: unresolved import `something::Foo`.\n```\n\nIn Rust 2015, paths in `use` statements are relative to the crate root. To\nimport items relative to the current and parent modules, use the `self::` and\n`super::` prefixes, respectively.\n\nIn Rust 2018 or later, paths in `use` statements are relative to the current\nmodule unless they begin with the name of a crate or a literal `crate::`, in\nwhich case they start from the crate root. As in Rust 2015 code, the `self::`\nand `super::` prefixes refer to the current and parent modules respectively.\n\nAlso verify that you didn't misspell the import name and that the import exists\nin the module from where you tried to import it. Example:\n\n```\nuse self::something::Foo; // Ok.\n\nmod something {\n    pub struct Foo;\n}\n# fn main() {}\n```\n\nIf you tried to use a module from an external crate and are using Rust 2015,\nyou may have missed the `extern crate` declaration (which is usually placed in\nthe crate root):\n\n```edition2015\nextern crate core; // Required to use the `core` crate in Rust 2015.\n\nuse core::any;\n# fn main() {}\n```\n\nSince Rust 2018 the `extern crate` declaration is not required and\nyou can instead just `use` it:\n\n```edition2018\nuse core::any; // No extern crate required in Rust 2018.\n# fn main() {}\n```\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":10482,"byte_end":10501,"line_start":362,"line_end":362,"column_start":13,"column_end":32,"is_primary":true,"text":[{"text":"        use ndarray_linalg::Dot;","highlight_start":13,"highlight_end":32}],"label":"no `Dot` in the root","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"consider importing this trait instead","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":10482,"byte_end":10501,"line_start":362,"line_end":362,"column_start":13,"column_end":32,"is_primary":true,"text":[{"text":"        use ndarray_linalg::Dot;","highlight_start":13,"highlight_end":32}],"label":null,"suggested_replacement":"ndarray::linalg::Dot","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0432]\u001b[0m\u001b[0m\u001b[1m: unresolved import `ndarray_linalg::Dot`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:362:13\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m362\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        use ndarray_linalg::Dot;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m             \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mno `Dot` in the root\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider importing this trait instead\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m362\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        use \u001b[0m\u001b[0m\u001b[38;5;10mndarray::linalg::Dot\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m             \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unresolved import `crate::nn::Embedding`","code":{"code":"E0432","explanation":"An import was unresolved.\n\nErroneous code example:\n\n```compile_fail,E0432\nuse something::Foo; // error: unresolved import `something::Foo`.\n```\n\nIn Rust 2015, paths in `use` statements are relative to the crate root. To\nimport items relative to the current and parent modules, use the `self::` and\n`super::` prefixes, respectively.\n\nIn Rust 2018 or later, paths in `use` statements are relative to the current\nmodule unless they begin with the name of a crate or a literal `crate::`, in\nwhich case they start from the crate root. As in Rust 2015 code, the `self::`\nand `super::` prefixes refer to the current and parent modules respectively.\n\nAlso verify that you didn't misspell the import name and that the import exists\nin the module from where you tried to import it. Example:\n\n```\nuse self::something::Foo; // Ok.\n\nmod something {\n    pub struct Foo;\n}\n# fn main() {}\n```\n\nIf you tried to use a module from an external crate and are using Rust 2015,\nyou may have missed the `extern crate` declaration (which is usually placed in\nthe crate root):\n\n```edition2015\nextern crate core; // Required to use the `core` crate in Rust 2015.\n\nuse core::any;\n# fn main() {}\n```\n\nSince Rust 2018 the `extern crate` declaration is not required and\nyou can instead just `use` it:\n\n```edition2018\nuse core::any; // No extern crate required in Rust 2018.\n# fn main() {}\n```\n"},"level":"error","spans":[{"file_name":"src/nlp/mod.rs","byte_start":119,"byte_end":128,"line_start":4,"line_end":4,"column_start":39,"column_end":48,"is_primary":true,"text":[{"text":"use crate::nn::{Module, Linear, LSTM, Embedding};","highlight_start":39,"highlight_end":48}],"label":"no `Embedding` in `nn`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0432]\u001b[0m\u001b[0m\u001b[1m: unresolved import `crate::nn::Embedding`\u001b[0m\n\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nlp/mod.rs:4:39\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m4\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse crate::nn::{Module, Linear, LSTM, Embedding};\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                       \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mno `Embedding` in `nn`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unnecessary parentheses around assigned value","code":{"code":"unused_parens","explanation":null},"level":"warning","spans":[{"file_name":"src/tensor.rs","byte_start":11571,"byte_end":11572,"line_start":396,"line_end":396,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"        let result_data = (&self.data + &other.data);","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/tensor.rs","byte_start":11596,"byte_end":11597,"line_start":396,"line_end":396,"column_start":52,"column_end":53,"is_primary":true,"text":[{"text":"        let result_data = (&self.data + &other.data);","highlight_start":52,"highlight_end":53}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_parens)]` on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"remove these parentheses","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":11571,"byte_end":11572,"line_start":396,"line_end":396,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"        let result_data = (&self.data + &other.data);","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/tensor.rs","byte_start":11596,"byte_end":11597,"line_start":396,"line_end":396,"column_start":52,"column_end":53,"is_primary":true,"text":[{"text":"        let result_data = (&self.data + &other.data);","highlight_start":52,"highlight_end":53}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unnecessary parentheses around assigned value\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:396:27\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m396\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let result_data = (&self.data + &other.data);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                           \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m                        \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: `#[warn(unused_parens)]` on by default\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: remove these parentheses\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m396\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;9m- \u001b[0m\u001b[0m        let result_data = \u001b[0m\u001b[0m\u001b[38;5;9m(\u001b[0m\u001b[0m&self.data + &other.data\u001b[0m\u001b[0m\u001b[38;5;9m)\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m396\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;10m+ \u001b[0m\u001b[0m        let result_data = &self.data + &other.data;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unnecessary parentheses around assigned value","code":{"code":"unused_parens","explanation":null},"level":"warning","spans":[{"file_name":"src/tensor.rs","byte_start":11896,"byte_end":11897,"line_start":405,"line_end":405,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"        let result_data = (&self.data - &other.data);","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/tensor.rs","byte_start":11921,"byte_end":11922,"line_start":405,"line_end":405,"column_start":52,"column_end":53,"is_primary":true,"text":[{"text":"        let result_data = (&self.data - &other.data);","highlight_start":52,"highlight_end":53}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove these parentheses","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":11896,"byte_end":11897,"line_start":405,"line_end":405,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"        let result_data = (&self.data - &other.data);","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/tensor.rs","byte_start":11921,"byte_end":11922,"line_start":405,"line_end":405,"column_start":52,"column_end":53,"is_primary":true,"text":[{"text":"        let result_data = (&self.data - &other.data);","highlight_start":52,"highlight_end":53}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unnecessary parentheses around assigned value\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:405:27\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m405\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let result_data = (&self.data - &other.data);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                           \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m                        \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: remove these parentheses\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m405\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;9m- \u001b[0m\u001b[0m        let result_data = \u001b[0m\u001b[0m\u001b[38;5;9m(\u001b[0m\u001b[0m&self.data - &other.data\u001b[0m\u001b[0m\u001b[38;5;9m)\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m405\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;10m+ \u001b[0m\u001b[0m        let result_data = &self.data - &other.data;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unnecessary parentheses around assigned value","code":{"code":"unused_parens","explanation":null},"level":"warning","spans":[{"file_name":"src/tensor.rs","byte_start":12221,"byte_end":12222,"line_start":414,"line_end":414,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"        let result_data = (&self.data * &other.data);","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/tensor.rs","byte_start":12246,"byte_end":12247,"line_start":414,"line_end":414,"column_start":52,"column_end":53,"is_primary":true,"text":[{"text":"        let result_data = (&self.data * &other.data);","highlight_start":52,"highlight_end":53}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove these parentheses","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":12221,"byte_end":12222,"line_start":414,"line_end":414,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"        let result_data = (&self.data * &other.data);","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/tensor.rs","byte_start":12246,"byte_end":12247,"line_start":414,"line_end":414,"column_start":52,"column_end":53,"is_primary":true,"text":[{"text":"        let result_data = (&self.data * &other.data);","highlight_start":52,"highlight_end":53}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unnecessary parentheses around assigned value\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:414:27\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m414\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let result_data = (&self.data * &other.data);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                           \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m                        \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: remove these parentheses\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m414\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;9m- \u001b[0m\u001b[0m        let result_data = \u001b[0m\u001b[0m\u001b[38;5;9m(\u001b[0m\u001b[0m&self.data * &other.data\u001b[0m\u001b[0m\u001b[38;5;9m)\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m414\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;10m+ \u001b[0m\u001b[0m        let result_data = &self.data * &other.data;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unnecessary parentheses around assigned value","code":{"code":"unused_parens","explanation":null},"level":"warning","spans":[{"file_name":"src/tensor.rs","byte_start":12546,"byte_end":12547,"line_start":423,"line_end":423,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"        let result_data = (&self.data / &other.data);","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/tensor.rs","byte_start":12571,"byte_end":12572,"line_start":423,"line_end":423,"column_start":52,"column_end":53,"is_primary":true,"text":[{"text":"        let result_data = (&self.data / &other.data);","highlight_start":52,"highlight_end":53}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove these parentheses","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":12546,"byte_end":12547,"line_start":423,"line_end":423,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"        let result_data = (&self.data / &other.data);","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/tensor.rs","byte_start":12571,"byte_end":12572,"line_start":423,"line_end":423,"column_start":52,"column_end":53,"is_primary":true,"text":[{"text":"        let result_data = (&self.data / &other.data);","highlight_start":52,"highlight_end":53}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unnecessary parentheses around assigned value\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:423:27\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m423\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let result_data = (&self.data / &other.data);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                           \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m                        \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: remove these parentheses\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m423\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;9m- \u001b[0m\u001b[0m        let result_data = \u001b[0m\u001b[0m\u001b[38;5;9m(\u001b[0m\u001b[0m&self.data / &other.data\u001b[0m\u001b[0m\u001b[38;5;9m)\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m423\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;10m+ \u001b[0m\u001b[0m        let result_data = &self.data / &other.data;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `anyhow`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"src/nn/conv.rs","byte_start":140,"byte_end":146,"line_start":5,"line_end":5,"column_start":22,"column_end":28,"is_primary":true,"text":[{"text":"use anyhow::{Result, anyhow};","highlight_start":22,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_imports)]` on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"remove the unused import","code":null,"level":"help","spans":[{"file_name":"src/nn/conv.rs","byte_start":138,"byte_end":146,"line_start":5,"line_end":5,"column_start":20,"column_end":28,"is_primary":true,"text":[{"text":"use anyhow::{Result, anyhow};","highlight_start":20,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/nn/conv.rs","byte_start":131,"byte_end":132,"line_start":5,"line_end":5,"column_start":13,"column_end":14,"is_primary":true,"text":[{"text":"use anyhow::{Result, anyhow};","highlight_start":13,"highlight_end":14}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/nn/conv.rs","byte_start":146,"byte_end":147,"line_start":5,"line_end":5,"column_start":28,"column_end":29,"is_primary":true,"text":[{"text":"use anyhow::{Result, anyhow};","highlight_start":28,"highlight_end":29}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused import: `anyhow`\u001b[0m\n\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/conv.rs:5:22\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m5\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse anyhow::{Result, anyhow};\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: `#[warn(unused_imports)]` on by default\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused imports: `InitType` and `init_parameter`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"src/nn/normalization.rs","byte_start":92,"byte_end":100,"line_start":4,"line_end":4,"column_start":25,"column_end":33,"is_primary":true,"text":[{"text":"use crate::nn::{Module, InitType, init_parameter};","highlight_start":25,"highlight_end":33}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/normalization.rs","byte_start":102,"byte_end":116,"line_start":4,"line_end":4,"column_start":35,"column_end":49,"is_primary":true,"text":[{"text":"use crate::nn::{Module, InitType, init_parameter};","highlight_start":35,"highlight_end":49}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the unused imports","code":null,"level":"help","spans":[{"file_name":"src/nn/normalization.rs","byte_start":90,"byte_end":116,"line_start":4,"line_end":4,"column_start":23,"column_end":49,"is_primary":true,"text":[{"text":"use crate::nn::{Module, InitType, init_parameter};","highlight_start":23,"highlight_end":49}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/nn/normalization.rs","byte_start":83,"byte_end":84,"line_start":4,"line_end":4,"column_start":16,"column_end":17,"is_primary":true,"text":[{"text":"use crate::nn::{Module, InitType, init_parameter};","highlight_start":16,"highlight_end":17}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/nn/normalization.rs","byte_start":116,"byte_end":117,"line_start":4,"line_end":4,"column_start":49,"column_end":50,"is_primary":true,"text":[{"text":"use crate::nn::{Module, InitType, init_parameter};","highlight_start":49,"highlight_end":50}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused imports: `InitType` and `init_parameter`\u001b[0m\n\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/normalization.rs:4:25\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m4\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse crate::nn::{Module, InitType, init_parameter};\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unnecessary parentheses around assigned value","code":{"code":"unused_parens","explanation":null},"level":"warning","spans":[{"file_name":"src/nn/pooling.rs","byte_start":1517,"byte_end":1518,"line_start":53,"line_end":53,"column_start":41,"column_end":42,"is_primary":true,"text":[{"text":"                        let input_idx = ((b * channels + c) * input_length + i);","highlight_start":41,"highlight_end":42}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/pooling.rs","byte_start":1555,"byte_end":1556,"line_start":53,"line_end":53,"column_start":79,"column_end":80,"is_primary":true,"text":[{"text":"                        let input_idx = ((b * channels + c) * input_length + i);","highlight_start":79,"highlight_end":80}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove these parentheses","code":null,"level":"help","spans":[{"file_name":"src/nn/pooling.rs","byte_start":1517,"byte_end":1518,"line_start":53,"line_end":53,"column_start":41,"column_end":42,"is_primary":true,"text":[{"text":"                        let input_idx = ((b * channels + c) * input_length + i);","highlight_start":41,"highlight_end":42}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/nn/pooling.rs","byte_start":1555,"byte_end":1556,"line_start":53,"line_end":53,"column_start":79,"column_end":80,"is_primary":true,"text":[{"text":"                        let input_idx = ((b * channels + c) * input_length + i);","highlight_start":79,"highlight_end":80}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unnecessary parentheses around assigned value\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/pooling.rs:53:41\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m53\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        let input_idx = ((b * channels + c) * input_length + i);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                         \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: remove these parentheses\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m53\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;9m- \u001b[0m\u001b[0m                        let input_idx = \u001b[0m\u001b[0m\u001b[38;5;9m(\u001b[0m\u001b[0m(b * channels + c) * input_length + i\u001b[0m\u001b[0m\u001b[38;5;9m)\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m53\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;10m+ \u001b[0m\u001b[0m                        let input_idx = (b * channels + c) * input_length + i;\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unnecessary parentheses around assigned value","code":{"code":"unused_parens","explanation":null},"level":"warning","spans":[{"file_name":"src/nn/pooling.rs","byte_start":6595,"byte_end":6596,"line_start":200,"line_end":200,"column_start":41,"column_end":42,"is_primary":true,"text":[{"text":"                        let input_idx = ((b * channels + c) * input_length + i);","highlight_start":41,"highlight_end":42}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/pooling.rs","byte_start":6633,"byte_end":6634,"line_start":200,"line_end":200,"column_start":79,"column_end":80,"is_primary":true,"text":[{"text":"                        let input_idx = ((b * channels + c) * input_length + i);","highlight_start":79,"highlight_end":80}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove these parentheses","code":null,"level":"help","spans":[{"file_name":"src/nn/pooling.rs","byte_start":6595,"byte_end":6596,"line_start":200,"line_end":200,"column_start":41,"column_end":42,"is_primary":true,"text":[{"text":"                        let input_idx = ((b * channels + c) * input_length + i);","highlight_start":41,"highlight_end":42}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/nn/pooling.rs","byte_start":6633,"byte_end":6634,"line_start":200,"line_end":200,"column_start":79,"column_end":80,"is_primary":true,"text":[{"text":"                        let input_idx = ((b * channels + c) * input_length + i);","highlight_start":79,"highlight_end":80}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unnecessary parentheses around assigned value\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/pooling.rs:200:41\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m200\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        let input_idx = ((b * channels + c) * input_length + i);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                         \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: remove these parentheses\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m200\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;9m- \u001b[0m\u001b[0m                        let input_idx = \u001b[0m\u001b[0m\u001b[38;5;9m(\u001b[0m\u001b[0m(b * channels + c) * input_length + i\u001b[0m\u001b[0m\u001b[38;5;9m)\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m200\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[38;5;10m+ \u001b[0m\u001b[0m                        let input_idx = (b * channels + c) * input_length + i;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused imports: `Deserialize` and `Serialize`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"src/nn/mod.rs","byte_start":379,"byte_end":388,"line_start":18,"line_end":18,"column_start":13,"column_end":22,"is_primary":true,"text":[{"text":"use serde::{Serialize, Deserialize};","highlight_start":13,"highlight_end":22}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":390,"byte_end":401,"line_start":18,"line_end":18,"column_start":24,"column_end":35,"is_primary":true,"text":[{"text":"use serde::{Serialize, Deserialize};","highlight_start":24,"highlight_end":35}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the whole `use` item","code":null,"level":"help","spans":[{"file_name":"src/nn/mod.rs","byte_start":367,"byte_end":404,"line_start":18,"line_end":19,"column_start":1,"column_end":1,"is_primary":true,"text":[{"text":"use serde::{Serialize, Deserialize};","highlight_start":1,"highlight_end":37},{"text":"use std::collections::HashMap;","highlight_start":1,"highlight_end":1}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused imports: `Deserialize` and `Serialize`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:18:13\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m18\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse serde::{Serialize, Deserialize};\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m             \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^^\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `std::collections::HashMap`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"src/nn/mod.rs","byte_start":408,"byte_end":433,"line_start":19,"line_end":19,"column_start":5,"column_end":30,"is_primary":true,"text":[{"text":"use std::collections::HashMap;","highlight_start":5,"highlight_end":30}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the whole `use` item","code":null,"level":"help","spans":[{"file_name":"src/nn/mod.rs","byte_start":404,"byte_end":435,"line_start":19,"line_end":20,"column_start":1,"column_end":1,"is_primary":true,"text":[{"text":"use std::collections::HashMap;","highlight_start":1,"highlight_end":31},{"text":"","highlight_start":1,"highlight_end":1}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused import: `std::collections::HashMap`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:19:5\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m19\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse std::collections::HashMap;\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `anyhow::Result`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"src/metrics/mod.rs","byte_start":69,"byte_end":83,"line_start":4,"line_end":4,"column_start":5,"column_end":19,"is_primary":true,"text":[{"text":"use anyhow::Result;","highlight_start":5,"highlight_end":19}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the whole `use` item","code":null,"level":"help","spans":[{"file_name":"src/metrics/mod.rs","byte_start":65,"byte_end":85,"line_start":4,"line_end":5,"column_start":1,"column_end":1,"is_primary":true,"text":[{"text":"use anyhow::Result;","highlight_start":1,"highlight_end":20},{"text":"","highlight_start":1,"highlight_end":1}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused import: `anyhow::Result`\u001b[0m\n\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/metrics/mod.rs:4:5\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m4\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse anyhow::Result;\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused import: `std::collections::HashMap`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"src/distributed/mod.rs","byte_start":87,"byte_end":112,"line_start":5,"line_end":5,"column_start":5,"column_end":30,"is_primary":true,"text":[{"text":"use std::collections::HashMap;","highlight_start":5,"highlight_end":30}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"remove the whole `use` item","code":null,"level":"help","spans":[{"file_name":"src/distributed/mod.rs","byte_start":83,"byte_end":114,"line_start":5,"line_end":6,"column_start":1,"column_end":1,"is_primary":true,"text":[{"text":"use std::collections::HashMap;","highlight_start":1,"highlight_end":31},{"text":"","highlight_start":1,"highlight_end":1}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused import: `std::collections::HashMap`\u001b[0m\n\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/distributed/mod.rs:5:5\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m5\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse std::collections::HashMap;\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"the size for values of type `Self` cannot be known at compilation time","code":{"code":"E0277","explanation":"You tried to use a type which doesn't implement some trait in a place which\nexpected that trait.\n\nErroneous code example:\n\n```compile_fail,E0277\n// here we declare the Foo trait with a bar method\ntrait Foo {\n    fn bar(&self);\n}\n\n// we now declare a function which takes an object implementing the Foo trait\nfn some_func<T: Foo>(foo: T) {\n    foo.bar();\n}\n\nfn main() {\n    // we now call the method with the i32 type, which doesn't implement\n    // the Foo trait\n    some_func(5i32); // error: the trait bound `i32 : Foo` is not satisfied\n}\n```\n\nIn order to fix this error, verify that the type you're using does implement\nthe trait. Example:\n\n```\ntrait Foo {\n    fn bar(&self);\n}\n\n// we implement the trait on the i32 type\nimpl Foo for i32 {\n    fn bar(&self) {}\n}\n\nfn some_func<T: Foo>(foo: T) {\n    foo.bar(); // we can now use this method since i32 implements the\n               // Foo trait\n}\n\nfn main() {\n    some_func(5i32); // ok!\n}\n```\n\nOr in a generic context, an erroneous code example would look like:\n\n```compile_fail,E0277\nfn some_func<T>(foo: T) {\n    println!(\"{:?}\", foo); // error: the trait `core::fmt::Debug` is not\n                           //        implemented for the type `T`\n}\n\nfn main() {\n    // We now call the method with the i32 type,\n    // which *does* implement the Debug trait.\n    some_func(5i32);\n}\n```\n\nNote that the error here is in the definition of the generic function. Although\nwe only call it with a parameter that does implement `Debug`, the compiler\nstill rejects the function. It must work with all possible input types. In\norder to make this example compile, we need to restrict the generic type we're\naccepting:\n\n```\nuse std::fmt;\n\n// Restrict the input type to types that implement Debug.\nfn some_func<T: fmt::Debug>(foo: T) {\n    println!(\"{:?}\", foo);\n}\n\nfn main() {\n    // Calling the method is still fine, as i32 implements Debug.\n    some_func(5i32);\n\n    // This would fail to compile now:\n    // struct WithoutDebug;\n    // some_func(WithoutDebug);\n}\n```\n\nRust only looks at the signature of the called function, as such it must\nalready specify all requirements that will be used for every type parameter.\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":11303,"byte_end":11315,"line_start":388,"line_end":388,"column_start":36,"column_end":48,"is_primary":true,"text":[{"text":"    fn add(&self, other: &Self) -> Result<Self>;","highlight_start":36,"highlight_end":48}],"label":"doesn't have a size known at compile-time","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"required by an implicit `Sized` bound in `std::result::Result`","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/result.rs","byte_start":19613,"byte_end":19614,"line_start":528,"line_end":528,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"pub enum Result<T, E> {","highlight_start":17,"highlight_end":18}],"label":"required by the implicit `Sized` requirement on this type parameter in `Result`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"consider further restricting `Self`","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":11315,"byte_end":11315,"line_start":388,"line_end":388,"column_start":48,"column_end":48,"is_primary":true,"text":[{"text":"    fn add(&self, other: &Self) -> Result<Self>;","highlight_start":48,"highlight_end":48}],"label":null,"suggested_replacement":" where Self: Sized","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0277]\u001b[0m\u001b[0m\u001b[1m: the size for values of type `Self` cannot be known at compilation time\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:388:36\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m388\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn add(&self, other: &Self) -> Result<Self>;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mdoesn't have a size known at compile-time\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: required by an implicit `Sized` bound in `std::result::Result`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/result.rs:528:17\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m528\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub enum Result<T, E> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mrequired by the implicit `Sized` requirement on this type parameter in `Result`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider further restricting `Self`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m388\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m    fn add(&self, other: &Self) -> Result<Self>\u001b[0m\u001b[0m\u001b[38;5;10m where Self: Sized\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                 \u001b[0m\u001b[0m\u001b[38;5;10m+++++++++++++++++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"the size for values of type `Self` cannot be known at compilation time","code":{"code":"E0277","explanation":"You tried to use a type which doesn't implement some trait in a place which\nexpected that trait.\n\nErroneous code example:\n\n```compile_fail,E0277\n// here we declare the Foo trait with a bar method\ntrait Foo {\n    fn bar(&self);\n}\n\n// we now declare a function which takes an object implementing the Foo trait\nfn some_func<T: Foo>(foo: T) {\n    foo.bar();\n}\n\nfn main() {\n    // we now call the method with the i32 type, which doesn't implement\n    // the Foo trait\n    some_func(5i32); // error: the trait bound `i32 : Foo` is not satisfied\n}\n```\n\nIn order to fix this error, verify that the type you're using does implement\nthe trait. Example:\n\n```\ntrait Foo {\n    fn bar(&self);\n}\n\n// we implement the trait on the i32 type\nimpl Foo for i32 {\n    fn bar(&self) {}\n}\n\nfn some_func<T: Foo>(foo: T) {\n    foo.bar(); // we can now use this method since i32 implements the\n               // Foo trait\n}\n\nfn main() {\n    some_func(5i32); // ok!\n}\n```\n\nOr in a generic context, an erroneous code example would look like:\n\n```compile_fail,E0277\nfn some_func<T>(foo: T) {\n    println!(\"{:?}\", foo); // error: the trait `core::fmt::Debug` is not\n                           //        implemented for the type `T`\n}\n\nfn main() {\n    // We now call the method with the i32 type,\n    // which *does* implement the Debug trait.\n    some_func(5i32);\n}\n```\n\nNote that the error here is in the definition of the generic function. Although\nwe only call it with a parameter that does implement `Debug`, the compiler\nstill rejects the function. It must work with all possible input types. In\norder to make this example compile, we need to restrict the generic type we're\naccepting:\n\n```\nuse std::fmt;\n\n// Restrict the input type to types that implement Debug.\nfn some_func<T: fmt::Debug>(foo: T) {\n    println!(\"{:?}\", foo);\n}\n\nfn main() {\n    // Calling the method is still fine, as i32 implements Debug.\n    some_func(5i32);\n\n    // This would fail to compile now:\n    // struct WithoutDebug;\n    // some_func(WithoutDebug);\n}\n```\n\nRust only looks at the signature of the called function, as such it must\nalready specify all requirements that will be used for every type parameter.\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":11352,"byte_end":11364,"line_start":389,"line_end":389,"column_start":36,"column_end":48,"is_primary":true,"text":[{"text":"    fn sub(&self, other: &Self) -> Result<Self>;","highlight_start":36,"highlight_end":48}],"label":"doesn't have a size known at compile-time","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"required by an implicit `Sized` bound in `std::result::Result`","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/result.rs","byte_start":19613,"byte_end":19614,"line_start":528,"line_end":528,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"pub enum Result<T, E> {","highlight_start":17,"highlight_end":18}],"label":"required by the implicit `Sized` requirement on this type parameter in `Result`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"consider further restricting `Self`","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":11364,"byte_end":11364,"line_start":389,"line_end":389,"column_start":48,"column_end":48,"is_primary":true,"text":[{"text":"    fn sub(&self, other: &Self) -> Result<Self>;","highlight_start":48,"highlight_end":48}],"label":null,"suggested_replacement":" where Self: Sized","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0277]\u001b[0m\u001b[0m\u001b[1m: the size for values of type `Self` cannot be known at compilation time\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:389:36\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m389\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn sub(&self, other: &Self) -> Result<Self>;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mdoesn't have a size known at compile-time\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: required by an implicit `Sized` bound in `std::result::Result`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/result.rs:528:17\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m528\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub enum Result<T, E> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mrequired by the implicit `Sized` requirement on this type parameter in `Result`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider further restricting `Self`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m389\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m    fn sub(&self, other: &Self) -> Result<Self>\u001b[0m\u001b[0m\u001b[38;5;10m where Self: Sized\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                 \u001b[0m\u001b[0m\u001b[38;5;10m+++++++++++++++++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"the size for values of type `Self` cannot be known at compilation time","code":{"code":"E0277","explanation":"You tried to use a type which doesn't implement some trait in a place which\nexpected that trait.\n\nErroneous code example:\n\n```compile_fail,E0277\n// here we declare the Foo trait with a bar method\ntrait Foo {\n    fn bar(&self);\n}\n\n// we now declare a function which takes an object implementing the Foo trait\nfn some_func<T: Foo>(foo: T) {\n    foo.bar();\n}\n\nfn main() {\n    // we now call the method with the i32 type, which doesn't implement\n    // the Foo trait\n    some_func(5i32); // error: the trait bound `i32 : Foo` is not satisfied\n}\n```\n\nIn order to fix this error, verify that the type you're using does implement\nthe trait. Example:\n\n```\ntrait Foo {\n    fn bar(&self);\n}\n\n// we implement the trait on the i32 type\nimpl Foo for i32 {\n    fn bar(&self) {}\n}\n\nfn some_func<T: Foo>(foo: T) {\n    foo.bar(); // we can now use this method since i32 implements the\n               // Foo trait\n}\n\nfn main() {\n    some_func(5i32); // ok!\n}\n```\n\nOr in a generic context, an erroneous code example would look like:\n\n```compile_fail,E0277\nfn some_func<T>(foo: T) {\n    println!(\"{:?}\", foo); // error: the trait `core::fmt::Debug` is not\n                           //        implemented for the type `T`\n}\n\nfn main() {\n    // We now call the method with the i32 type,\n    // which *does* implement the Debug trait.\n    some_func(5i32);\n}\n```\n\nNote that the error here is in the definition of the generic function. Although\nwe only call it with a parameter that does implement `Debug`, the compiler\nstill rejects the function. It must work with all possible input types. In\norder to make this example compile, we need to restrict the generic type we're\naccepting:\n\n```\nuse std::fmt;\n\n// Restrict the input type to types that implement Debug.\nfn some_func<T: fmt::Debug>(foo: T) {\n    println!(\"{:?}\", foo);\n}\n\nfn main() {\n    // Calling the method is still fine, as i32 implements Debug.\n    some_func(5i32);\n\n    // This would fail to compile now:\n    // struct WithoutDebug;\n    // some_func(WithoutDebug);\n}\n```\n\nRust only looks at the signature of the called function, as such it must\nalready specify all requirements that will be used for every type parameter.\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":11401,"byte_end":11413,"line_start":390,"line_end":390,"column_start":36,"column_end":48,"is_primary":true,"text":[{"text":"    fn mul(&self, other: &Self) -> Result<Self>;","highlight_start":36,"highlight_end":48}],"label":"doesn't have a size known at compile-time","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"required by an implicit `Sized` bound in `std::result::Result`","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/result.rs","byte_start":19613,"byte_end":19614,"line_start":528,"line_end":528,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"pub enum Result<T, E> {","highlight_start":17,"highlight_end":18}],"label":"required by the implicit `Sized` requirement on this type parameter in `Result`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"consider further restricting `Self`","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":11413,"byte_end":11413,"line_start":390,"line_end":390,"column_start":48,"column_end":48,"is_primary":true,"text":[{"text":"    fn mul(&self, other: &Self) -> Result<Self>;","highlight_start":48,"highlight_end":48}],"label":null,"suggested_replacement":" where Self: Sized","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0277]\u001b[0m\u001b[0m\u001b[1m: the size for values of type `Self` cannot be known at compilation time\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:390:36\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m390\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn mul(&self, other: &Self) -> Result<Self>;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mdoesn't have a size known at compile-time\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: required by an implicit `Sized` bound in `std::result::Result`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/result.rs:528:17\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m528\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub enum Result<T, E> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mrequired by the implicit `Sized` requirement on this type parameter in `Result`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider further restricting `Self`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m390\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m    fn mul(&self, other: &Self) -> Result<Self>\u001b[0m\u001b[0m\u001b[38;5;10m where Self: Sized\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                 \u001b[0m\u001b[0m\u001b[38;5;10m+++++++++++++++++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"the size for values of type `Self` cannot be known at compilation time","code":{"code":"E0277","explanation":"You tried to use a type which doesn't implement some trait in a place which\nexpected that trait.\n\nErroneous code example:\n\n```compile_fail,E0277\n// here we declare the Foo trait with a bar method\ntrait Foo {\n    fn bar(&self);\n}\n\n// we now declare a function which takes an object implementing the Foo trait\nfn some_func<T: Foo>(foo: T) {\n    foo.bar();\n}\n\nfn main() {\n    // we now call the method with the i32 type, which doesn't implement\n    // the Foo trait\n    some_func(5i32); // error: the trait bound `i32 : Foo` is not satisfied\n}\n```\n\nIn order to fix this error, verify that the type you're using does implement\nthe trait. Example:\n\n```\ntrait Foo {\n    fn bar(&self);\n}\n\n// we implement the trait on the i32 type\nimpl Foo for i32 {\n    fn bar(&self) {}\n}\n\nfn some_func<T: Foo>(foo: T) {\n    foo.bar(); // we can now use this method since i32 implements the\n               // Foo trait\n}\n\nfn main() {\n    some_func(5i32); // ok!\n}\n```\n\nOr in a generic context, an erroneous code example would look like:\n\n```compile_fail,E0277\nfn some_func<T>(foo: T) {\n    println!(\"{:?}\", foo); // error: the trait `core::fmt::Debug` is not\n                           //        implemented for the type `T`\n}\n\nfn main() {\n    // We now call the method with the i32 type,\n    // which *does* implement the Debug trait.\n    some_func(5i32);\n}\n```\n\nNote that the error here is in the definition of the generic function. Although\nwe only call it with a parameter that does implement `Debug`, the compiler\nstill rejects the function. It must work with all possible input types. In\norder to make this example compile, we need to restrict the generic type we're\naccepting:\n\n```\nuse std::fmt;\n\n// Restrict the input type to types that implement Debug.\nfn some_func<T: fmt::Debug>(foo: T) {\n    println!(\"{:?}\", foo);\n}\n\nfn main() {\n    // Calling the method is still fine, as i32 implements Debug.\n    some_func(5i32);\n\n    // This would fail to compile now:\n    // struct WithoutDebug;\n    // some_func(WithoutDebug);\n}\n```\n\nRust only looks at the signature of the called function, as such it must\nalready specify all requirements that will be used for every type parameter.\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":11450,"byte_end":11462,"line_start":391,"line_end":391,"column_start":36,"column_end":48,"is_primary":true,"text":[{"text":"    fn div(&self, other: &Self) -> Result<Self>;","highlight_start":36,"highlight_end":48}],"label":"doesn't have a size known at compile-time","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"required by an implicit `Sized` bound in `std::result::Result`","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/result.rs","byte_start":19613,"byte_end":19614,"line_start":528,"line_end":528,"column_start":17,"column_end":18,"is_primary":true,"text":[{"text":"pub enum Result<T, E> {","highlight_start":17,"highlight_end":18}],"label":"required by the implicit `Sized` requirement on this type parameter in `Result`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"consider further restricting `Self`","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":11462,"byte_end":11462,"line_start":391,"line_end":391,"column_start":48,"column_end":48,"is_primary":true,"text":[{"text":"    fn div(&self, other: &Self) -> Result<Self>;","highlight_start":48,"highlight_end":48}],"label":null,"suggested_replacement":" where Self: Sized","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0277]\u001b[0m\u001b[0m\u001b[1m: the size for values of type `Self` cannot be known at compilation time\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:391:36\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m391\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn div(&self, other: &Self) -> Result<Self>;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mdoesn't have a size known at compile-time\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: required by an implicit `Sized` bound in `std::result::Result`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/result.rs:528:17\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m528\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub enum Result<T, E> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mrequired by the implicit `Sized` requirement on this type parameter in `Result`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider further restricting `Self`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m391\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m    fn div(&self, other: &Self) -> Result<Self>\u001b[0m\u001b[0m\u001b[38;5;10m where Self: Sized\u001b[0m\u001b[0m;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                 \u001b[0m\u001b[0m\u001b[38;5;10m+++++++++++++++++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `i`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src/data/mod.rs","byte_start":10807,"byte_end":10808,"line_start":363,"line_end":363,"column_start":18,"column_end":19,"is_primary":true,"text":[{"text":"            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {","highlight_start":18,"highlight_end":19}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_variables)]` on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src/data/mod.rs","byte_start":10807,"byte_end":10808,"line_start":363,"line_end":363,"column_start":18,"column_end":19,"is_primary":true,"text":[{"text":"            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {","highlight_start":18,"highlight_end":19}],"label":null,"suggested_replacement":"_i","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused variable: `i`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/data/mod.rs:363:18\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m363\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                  \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_i`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: `#[warn(unused_variables)]` on by default\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `m`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src/data/mod.rs","byte_start":10812,"byte_end":10813,"line_start":363,"line_end":363,"column_start":23,"column_end":24,"is_primary":true,"text":[{"text":"            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {","highlight_start":23,"highlight_end":24}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src/data/mod.rs","byte_start":10812,"byte_end":10813,"line_start":363,"line_end":363,"column_start":23,"column_end":24,"is_primary":true,"text":[{"text":"            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {","highlight_start":23,"highlight_end":24}],"label":null,"suggested_replacement":"_m","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused variable: `m`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/data/mod.rs:363:23\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m363\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                       \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_m`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `s`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src/data/mod.rs","byte_start":10816,"byte_end":10817,"line_start":363,"line_end":363,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src/data/mod.rs","byte_start":10816,"byte_end":10817,"line_start":363,"line_end":363,"column_start":27,"column_end":28,"is_primary":true,"text":[{"text":"            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {","highlight_start":27,"highlight_end":28}],"label":null,"suggested_replacement":"_s","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: unused variable: `s`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/data/mod.rs:363:27\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m363\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            for (i, (&m, &s)) in mean.iter().zip(std.iter()).enumerate() {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                           \u001b[0m\u001b[0m\u001b[1m\u001b[33m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[33mhelp: if this is intentional, prefix it with an underscore: `_s`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"variable does not need to be mutable","code":{"code":"unused_mut","explanation":null},"level":"warning","spans":[{"file_name":"src/data/mod.rs","byte_start":10697,"byte_end":10711,"line_start":361,"line_end":361,"column_start":17,"column_end":31,"is_primary":true,"text":[{"text":"            let mut normalized = tensor.clone_tensor();","highlight_start":17,"highlight_end":31}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_mut)]` on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"remove this `mut`","code":null,"level":"help","spans":[{"file_name":"src/data/mod.rs","byte_start":10697,"byte_end":10701,"line_start":361,"line_end":361,"column_start":17,"column_end":21,"is_primary":true,"text":[{"text":"            let mut normalized = tensor.clone_tensor();","highlight_start":17,"highlight_end":21}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[33mwarning\u001b[0m\u001b[0m\u001b[1m: variable does not need to be mutable\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/data/mod.rs:361:17\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m361\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            let mut normalized = tensor.clone_tensor();\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----\u001b[0m\u001b[0m\u001b[1m\u001b[33m^^^^^^^^^^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mhelp: remove this `mut`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: `#[warn(unused_mut)]` on by default\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"no method named `to_vec` found for struct `ArrayBase<OwnedRepr<f32>, Dim<IxDynImpl>>` in the current scope","code":{"code":"E0599","explanation":"This error occurs when a method is used on a type which doesn't implement it:\n\nErroneous code example:\n\n```compile_fail,E0599\nstruct Mouth;\n\nlet x = Mouth;\nx.chocolate(); // error: no method named `chocolate` found for type `Mouth`\n               //        in the current scope\n```\n\nIn this case, you need to implement the `chocolate` method to fix the error:\n\n```\nstruct Mouth;\n\nimpl Mouth {\n    fn chocolate(&self) { // We implement the `chocolate` method here.\n        println!(\"Hmmm! I love chocolate!\");\n    }\n}\n\nlet x = Mouth;\nx.chocolate(); // ok!\n```\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":6754,"byte_end":6760,"line_start":239,"line_end":239,"column_start":19,"column_end":25,"is_primary":true,"text":[{"text":"        self.data.to_vec()","highlight_start":19,"highlight_end":25}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"there is a method `into_raw_vec` with a similar name","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":6754,"byte_end":6760,"line_start":239,"line_end":239,"column_start":19,"column_end":25,"is_primary":true,"text":[{"text":"        self.data.to_vec()","highlight_start":19,"highlight_end":25}],"label":null,"suggested_replacement":"into_raw_vec","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0599]\u001b[0m\u001b[0m\u001b[1m: no method named `to_vec` found for struct `ArrayBase<OwnedRepr<f32>, Dim<IxDynImpl>>` in the current scope\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:239:19\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m239\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        self.data.to_vec()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: there is a method `into_raw_vec` with a similar name\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m239\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        self.data.\u001b[0m\u001b[0m\u001b[38;5;10minto_raw_vec\u001b[0m\u001b[0m()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                   \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"overflow evaluating the requirement `&ArrayBase<_, _>: Not`","code":{"code":"E0275","explanation":"An evaluation of a trait requirement overflowed.\n\nErroneous code example:\n\n```compile_fail,E0275\ntrait Foo {}\n\nstruct Bar<T>(T);\n\nimpl<T> Foo for T where Bar<T>: Foo {}\n```\n\nThis error occurs when there was a recursive trait requirement that overflowed\nbefore it could be evaluated. This often means that there is an unbounded\nrecursion in resolving some type bounds.\n\nTo determine if a `T` is `Foo`, we need to check if `Bar<T>` is `Foo`. However,\nto do this check, we need to determine that `Bar<Bar<T>>` is `Foo`. To\ndetermine this, we check if `Bar<Bar<Bar<T>>>` is `Foo`, and so on. This is\nclearly a recursive requirement that can't be resolved directly.\n\nConsider changing your trait bounds so that they're less self-referential.\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":10711,"byte_end":10714,"line_start":368,"line_end":368,"column_start":37,"column_end":40,"is_primary":true,"text":[{"text":"        let result_data = self.data.dot(&other.data);","highlight_start":37,"highlight_end":40}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"consider increasing the recursion limit by adding a `#![recursion_limit = \"256\"]` attribute to your crate (`rust_ml_framework`)","code":null,"level":"help","spans":[],"children":[],"rendered":null},{"message":"required for `&ArrayBase<_, _>` to implement `Not`","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"127 redundant requirements hidden","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"required for `&ArrayBase<OwnedRepr<f32>, Dim<IxDynImpl>>` to implement `Not`","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0275]\u001b[0m\u001b[0m\u001b[1m: overflow evaluating the requirement `&ArrayBase<_, _>: Not`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:368:37\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m368\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let result_data = self.data.dot(&other.data);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mhelp\u001b[0m\u001b[0m: consider increasing the recursion limit by adding a `#![recursion_limit = \"256\"]` attribute to your crate (`rust_ml_framework`)\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: required for `&ArrayBase<_, _>` to implement `Not`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: 127 redundant requirements hidden\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: required for `&ArrayBase<OwnedRepr<f32>, Dim<IxDynImpl>>` to implement `Not`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"multiple applicable items in scope","code":{"code":"E0034","explanation":"The compiler doesn't know what method to call because more than one method\nhas the same prototype.\n\nErroneous code example:\n\n```compile_fail,E0034\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\ntrait Trait2 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\nimpl Trait2 for Test { fn foo() {} }\n\nfn main() {\n    Test::foo() // error, which foo() to call?\n}\n```\n\nTo avoid this error, you have to keep only one of them and remove the others.\nSo let's take our example and fix it:\n\n```\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\n\nfn main() {\n    Test::foo() // and now that's good!\n}\n```\n\nHowever, a better solution would be using fully explicit naming of type and\ntrait:\n\n```\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\ntrait Trait2 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\nimpl Trait2 for Test { fn foo() {} }\n\nfn main() {\n    <Test as Trait1>::foo()\n}\n```\n\nOne last example:\n\n```\ntrait F {\n    fn m(&self);\n}\n\ntrait G {\n    fn m(&self);\n}\n\nstruct X;\n\nimpl F for X { fn m(&self) { println!(\"I am F\"); } }\nimpl G for X { fn m(&self) { println!(\"I am G\"); } }\n\nfn main() {\n    let f = X;\n\n    F::m(&f); // it displays \"I am F\"\n    G::m(&f); // it displays \"I am G\"\n}\n```\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":12940,"byte_end":12943,"line_start":437,"line_end":437,"column_start":14,"column_end":17,"is_primary":true,"text":[{"text":"        self.add(other).unwrap()","highlight_start":14,"highlight_end":17}],"label":"multiple `add` found","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"candidate #1 is defined in an impl of the trait `Add` for the type `&tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":12883,"byte_end":12924,"line_start":436,"line_end":436,"column_start":5,"column_end":46,"is_primary":true,"text":[{"text":"    fn add(self, other: Self) -> Self::Output {","highlight_start":5,"highlight_end":46}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"candidate #2 is defined in an impl of the trait `TensorOps` for the type `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":11499,"byte_end":11542,"line_start":395,"line_end":395,"column_start":5,"column_end":48,"is_primary":true,"text":[{"text":"    fn add(&self, other: &Self) -> Result<Self> {","highlight_start":5,"highlight_end":48}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"disambiguate the method for candidate #1","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":12935,"byte_end":12950,"line_start":437,"line_end":437,"column_start":9,"column_end":24,"is_primary":true,"text":[{"text":"        self.add(other).unwrap()","highlight_start":9,"highlight_end":24}],"label":null,"suggested_replacement":"Add::add(&self, other)","suggestion_applicability":"HasPlaceholders","expansion":null}],"children":[],"rendered":null},{"message":"disambiguate the method for candidate #2","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":12935,"byte_end":12950,"line_start":437,"line_end":437,"column_start":9,"column_end":24,"is_primary":true,"text":[{"text":"        self.add(other).unwrap()","highlight_start":9,"highlight_end":24}],"label":null,"suggested_replacement":"TensorOps::add(&self, other)","suggestion_applicability":"HasPlaceholders","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0034]\u001b[0m\u001b[0m\u001b[1m: multiple applicable items in scope\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:437:14\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m437\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        self.add(other).unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mmultiple `add` found\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: candidate #1 is defined in an impl of the trait `Add` for the type `&tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:436:5\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m436\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn add(self, other: Self) -> Self::Output {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: candidate #2 is defined in an impl of the trait `TensorOps` for the type `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:395:5\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m395\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn add(&self, other: &Self) -> Result<Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: disambiguate the method for candidate #1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m437\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        \u001b[0m\u001b[0m\u001b[38;5;10mAdd::add(&self, other)\u001b[0m\u001b[0m.unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: disambiguate the method for candidate #2\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m437\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        \u001b[0m\u001b[0m\u001b[38;5;10mTensorOps::add(&self, other)\u001b[0m\u001b[0m.unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"multiple applicable items in scope","code":{"code":"E0034","explanation":"The compiler doesn't know what method to call because more than one method\nhas the same prototype.\n\nErroneous code example:\n\n```compile_fail,E0034\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\ntrait Trait2 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\nimpl Trait2 for Test { fn foo() {} }\n\nfn main() {\n    Test::foo() // error, which foo() to call?\n}\n```\n\nTo avoid this error, you have to keep only one of them and remove the others.\nSo let's take our example and fix it:\n\n```\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\n\nfn main() {\n    Test::foo() // and now that's good!\n}\n```\n\nHowever, a better solution would be using fully explicit naming of type and\ntrait:\n\n```\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\ntrait Trait2 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\nimpl Trait2 for Test { fn foo() {} }\n\nfn main() {\n    <Test as Trait1>::foo()\n}\n```\n\nOne last example:\n\n```\ntrait F {\n    fn m(&self);\n}\n\ntrait G {\n    fn m(&self);\n}\n\nstruct X;\n\nimpl F for X { fn m(&self) { println!(\"I am F\"); } }\nimpl G for X { fn m(&self) { println!(\"I am G\"); } }\n\nfn main() {\n    let f = X;\n\n    F::m(&f); // it displays \"I am F\"\n    G::m(&f); // it displays \"I am G\"\n}\n```\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":13080,"byte_end":13083,"line_start":445,"line_end":445,"column_start":14,"column_end":17,"is_primary":true,"text":[{"text":"        self.sub(other).unwrap()","highlight_start":14,"highlight_end":17}],"label":"multiple `sub` found","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"candidate #1 is defined in an impl of the trait `Sub` for the type `&tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":13023,"byte_end":13064,"line_start":444,"line_end":444,"column_start":5,"column_end":46,"is_primary":true,"text":[{"text":"    fn sub(self, other: Self) -> Self::Output {","highlight_start":5,"highlight_end":46}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"candidate #2 is defined in an impl of the trait `TensorOps` for the type `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":11824,"byte_end":11867,"line_start":404,"line_end":404,"column_start":5,"column_end":48,"is_primary":true,"text":[{"text":"    fn sub(&self, other: &Self) -> Result<Self> {","highlight_start":5,"highlight_end":48}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"disambiguate the method for candidate #1","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":13075,"byte_end":13090,"line_start":445,"line_end":445,"column_start":9,"column_end":24,"is_primary":true,"text":[{"text":"        self.sub(other).unwrap()","highlight_start":9,"highlight_end":24}],"label":null,"suggested_replacement":"Sub::sub(&self, other)","suggestion_applicability":"HasPlaceholders","expansion":null}],"children":[],"rendered":null},{"message":"disambiguate the method for candidate #2","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":13075,"byte_end":13090,"line_start":445,"line_end":445,"column_start":9,"column_end":24,"is_primary":true,"text":[{"text":"        self.sub(other).unwrap()","highlight_start":9,"highlight_end":24}],"label":null,"suggested_replacement":"TensorOps::sub(&self, other)","suggestion_applicability":"HasPlaceholders","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0034]\u001b[0m\u001b[0m\u001b[1m: multiple applicable items in scope\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:445:14\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m445\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        self.sub(other).unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mmultiple `sub` found\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: candidate #1 is defined in an impl of the trait `Sub` for the type `&tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:444:5\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m444\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn sub(self, other: Self) -> Self::Output {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: candidate #2 is defined in an impl of the trait `TensorOps` for the type `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:404:5\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m404\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn sub(&self, other: &Self) -> Result<Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: disambiguate the method for candidate #1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m445\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        \u001b[0m\u001b[0m\u001b[38;5;10mSub::sub(&self, other)\u001b[0m\u001b[0m.unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: disambiguate the method for candidate #2\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m445\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        \u001b[0m\u001b[0m\u001b[38;5;10mTensorOps::sub(&self, other)\u001b[0m\u001b[0m.unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"multiple applicable items in scope","code":{"code":"E0034","explanation":"The compiler doesn't know what method to call because more than one method\nhas the same prototype.\n\nErroneous code example:\n\n```compile_fail,E0034\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\ntrait Trait2 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\nimpl Trait2 for Test { fn foo() {} }\n\nfn main() {\n    Test::foo() // error, which foo() to call?\n}\n```\n\nTo avoid this error, you have to keep only one of them and remove the others.\nSo let's take our example and fix it:\n\n```\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\n\nfn main() {\n    Test::foo() // and now that's good!\n}\n```\n\nHowever, a better solution would be using fully explicit naming of type and\ntrait:\n\n```\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\ntrait Trait2 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\nimpl Trait2 for Test { fn foo() {} }\n\nfn main() {\n    <Test as Trait1>::foo()\n}\n```\n\nOne last example:\n\n```\ntrait F {\n    fn m(&self);\n}\n\ntrait G {\n    fn m(&self);\n}\n\nstruct X;\n\nimpl F for X { fn m(&self) { println!(\"I am F\"); } }\nimpl G for X { fn m(&self) { println!(\"I am G\"); } }\n\nfn main() {\n    let f = X;\n\n    F::m(&f); // it displays \"I am F\"\n    G::m(&f); // it displays \"I am G\"\n}\n```\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":13220,"byte_end":13223,"line_start":453,"line_end":453,"column_start":14,"column_end":17,"is_primary":true,"text":[{"text":"        self.mul(other).unwrap()","highlight_start":14,"highlight_end":17}],"label":"multiple `mul` found","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"candidate #1 is defined in an impl of the trait `Mul` for the type `&tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":13163,"byte_end":13204,"line_start":452,"line_end":452,"column_start":5,"column_end":46,"is_primary":true,"text":[{"text":"    fn mul(self, other: Self) -> Self::Output {","highlight_start":5,"highlight_end":46}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"candidate #2 is defined in an impl of the trait `TensorOps` for the type `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":12149,"byte_end":12192,"line_start":413,"line_end":413,"column_start":5,"column_end":48,"is_primary":true,"text":[{"text":"    fn mul(&self, other: &Self) -> Result<Self> {","highlight_start":5,"highlight_end":48}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"disambiguate the method for candidate #1","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":13215,"byte_end":13230,"line_start":453,"line_end":453,"column_start":9,"column_end":24,"is_primary":true,"text":[{"text":"        self.mul(other).unwrap()","highlight_start":9,"highlight_end":24}],"label":null,"suggested_replacement":"Mul::mul(&self, other)","suggestion_applicability":"HasPlaceholders","expansion":null}],"children":[],"rendered":null},{"message":"disambiguate the method for candidate #2","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":13215,"byte_end":13230,"line_start":453,"line_end":453,"column_start":9,"column_end":24,"is_primary":true,"text":[{"text":"        self.mul(other).unwrap()","highlight_start":9,"highlight_end":24}],"label":null,"suggested_replacement":"TensorOps::mul(&self, other)","suggestion_applicability":"HasPlaceholders","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0034]\u001b[0m\u001b[0m\u001b[1m: multiple applicable items in scope\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:453:14\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m453\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        self.mul(other).unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mmultiple `mul` found\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: candidate #1 is defined in an impl of the trait `Mul` for the type `&tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:452:5\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m452\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn mul(self, other: Self) -> Self::Output {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: candidate #2 is defined in an impl of the trait `TensorOps` for the type `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:413:5\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m413\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn mul(&self, other: &Self) -> Result<Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: disambiguate the method for candidate #1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m453\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        \u001b[0m\u001b[0m\u001b[38;5;10mMul::mul(&self, other)\u001b[0m\u001b[0m.unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: disambiguate the method for candidate #2\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m453\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        \u001b[0m\u001b[0m\u001b[38;5;10mTensorOps::mul(&self, other)\u001b[0m\u001b[0m.unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"multiple applicable items in scope","code":{"code":"E0034","explanation":"The compiler doesn't know what method to call because more than one method\nhas the same prototype.\n\nErroneous code example:\n\n```compile_fail,E0034\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\ntrait Trait2 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\nimpl Trait2 for Test { fn foo() {} }\n\nfn main() {\n    Test::foo() // error, which foo() to call?\n}\n```\n\nTo avoid this error, you have to keep only one of them and remove the others.\nSo let's take our example and fix it:\n\n```\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\n\nfn main() {\n    Test::foo() // and now that's good!\n}\n```\n\nHowever, a better solution would be using fully explicit naming of type and\ntrait:\n\n```\nstruct Test;\n\ntrait Trait1 {\n    fn foo();\n}\n\ntrait Trait2 {\n    fn foo();\n}\n\nimpl Trait1 for Test { fn foo() {} }\nimpl Trait2 for Test { fn foo() {} }\n\nfn main() {\n    <Test as Trait1>::foo()\n}\n```\n\nOne last example:\n\n```\ntrait F {\n    fn m(&self);\n}\n\ntrait G {\n    fn m(&self);\n}\n\nstruct X;\n\nimpl F for X { fn m(&self) { println!(\"I am F\"); } }\nimpl G for X { fn m(&self) { println!(\"I am G\"); } }\n\nfn main() {\n    let f = X;\n\n    F::m(&f); // it displays \"I am F\"\n    G::m(&f); // it displays \"I am G\"\n}\n```\n"},"level":"error","spans":[{"file_name":"src/tensor.rs","byte_start":13360,"byte_end":13363,"line_start":461,"line_end":461,"column_start":14,"column_end":17,"is_primary":true,"text":[{"text":"        self.div(other).unwrap()","highlight_start":14,"highlight_end":17}],"label":"multiple `div` found","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"candidate #1 is defined in an impl of the trait `Div` for the type `&tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":13303,"byte_end":13344,"line_start":460,"line_end":460,"column_start":5,"column_end":46,"is_primary":true,"text":[{"text":"    fn div(self, other: Self) -> Self::Output {","highlight_start":5,"highlight_end":46}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"candidate #2 is defined in an impl of the trait `TensorOps` for the type `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":12474,"byte_end":12517,"line_start":422,"line_end":422,"column_start":5,"column_end":48,"is_primary":true,"text":[{"text":"    fn div(&self, other: &Self) -> Result<Self> {","highlight_start":5,"highlight_end":48}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"disambiguate the method for candidate #1","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":13355,"byte_end":13370,"line_start":461,"line_end":461,"column_start":9,"column_end":24,"is_primary":true,"text":[{"text":"        self.div(other).unwrap()","highlight_start":9,"highlight_end":24}],"label":null,"suggested_replacement":"Div::div(&self, other)","suggestion_applicability":"HasPlaceholders","expansion":null}],"children":[],"rendered":null},{"message":"disambiguate the method for candidate #2","code":null,"level":"help","spans":[{"file_name":"src/tensor.rs","byte_start":13355,"byte_end":13370,"line_start":461,"line_end":461,"column_start":9,"column_end":24,"is_primary":true,"text":[{"text":"        self.div(other).unwrap()","highlight_start":9,"highlight_end":24}],"label":null,"suggested_replacement":"TensorOps::div(&self, other)","suggestion_applicability":"HasPlaceholders","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0034]\u001b[0m\u001b[0m\u001b[1m: multiple applicable items in scope\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:461:14\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m461\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        self.div(other).unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mmultiple `div` found\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: candidate #1 is defined in an impl of the trait `Div` for the type `&tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:460:5\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m460\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn div(self, other: Self) -> Self::Output {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: candidate #2 is defined in an impl of the trait `TensorOps` for the type `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:422:5\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m422\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    fn div(&self, other: &Self) -> Result<Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: disambiguate the method for candidate #1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m461\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        \u001b[0m\u001b[0m\u001b[38;5;10mDiv::div(&self, other)\u001b[0m\u001b[0m.unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: disambiguate the method for candidate #2\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m461\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        \u001b[0m\u001b[0m\u001b[38;5;10mTensorOps::div(&self, other)\u001b[0m\u001b[0m.unwrap()\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[38;5;10m~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/nn/activation.rs","byte_start":5148,"byte_end":5156,"line_start":239,"line_end":239,"column_start":41,"column_end":49,"is_primary":true,"text":[{"text":"        let term = input + &(&x_cubed * 0.044715);","highlight_start":41,"highlight_end":49}],"label":"expected `&Tensor`, found floating-point number","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/activation.rs:239:41\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m239\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let term = input + &(&x_cubed * 0.044715);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found floating-point number\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/nn/activation.rs","byte_start":5253,"byte_end":5262,"line_start":241,"line_end":241,"column_start":34,"column_end":43,"is_primary":true,"text":[{"text":"        let tanh_input = &term * sqrt_2_pi;","highlight_start":34,"highlight_end":43}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/activation.rs:241:34\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m241\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let tanh_input = &term * sqrt_2_pi;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/nn/activation.rs","byte_start":5342,"byte_end":5345,"line_start":244,"line_end":244,"column_start":37,"column_end":40,"is_primary":true,"text":[{"text":"        let exp_2x = (&tanh_input * 2.0).exp();","highlight_start":37,"highlight_end":40}],"label":"expected `&Tensor`, found floating-point number","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/activation.rs:244:37\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m244\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let exp_2x = (&tanh_input * 2.0).exp();\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found floating-point number\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot divide `tensor::Tensor` by `tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/activation.rs","byte_start":5424,"byte_end":5440,"line_start":246,"line_end":246,"column_start":24,"column_end":40,"is_primary":false,"text":[{"text":"        let tanh_val = (&exp_2x - &one) / (&exp_2x + &one);","highlight_start":24,"highlight_end":40}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/activation.rs","byte_start":5443,"byte_end":5459,"line_start":246,"line_end":246,"column_start":43,"column_end":59,"is_primary":false,"text":[{"text":"        let tanh_val = (&exp_2x - &one) / (&exp_2x + &one);","highlight_start":43,"highlight_end":59}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/activation.rs","byte_start":5441,"byte_end":5442,"line_start":246,"line_end":246,"column_start":41,"column_end":42,"is_primary":true,"text":[{"text":"        let tanh_val = (&exp_2x - &one) / (&exp_2x + &one);","highlight_start":41,"highlight_end":42}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Div` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Div`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Div` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":12611,"byte_end":12636,"line_start":462,"line_end":462,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Div<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot divide `tensor::Tensor` by `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/activation.rs:246:41\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m246\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let tanh_val = (&exp_2x - &one) / (&exp_2x + &one);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                        \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                        \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                        \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Div` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Div`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Div` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:462:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m462\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Div<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/nn/activation.rs","byte_start":5499,"byte_end":5502,"line_start":248,"line_end":248,"column_start":30,"column_end":33,"is_primary":true,"text":[{"text":"        let result = input * 0.5 * (&one + &tanh_val);","highlight_start":30,"highlight_end":33}],"label":"expected `&Tensor`, found floating-point number","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/activation.rs:248:30\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m248\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let result = input * 0.5 * (&one + &tanh_val);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found floating-point number\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/activation.rs","byte_start":5491,"byte_end":5502,"line_start":248,"line_end":248,"column_start":22,"column_end":33,"is_primary":false,"text":[{"text":"        let result = input * 0.5 * (&one + &tanh_val);","highlight_start":22,"highlight_end":33}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/activation.rs","byte_start":5505,"byte_end":5523,"line_start":248,"line_end":248,"column_start":36,"column_end":54,"is_primary":false,"text":[{"text":"        let result = input * 0.5 * (&one + &tanh_val);","highlight_start":36,"highlight_end":54}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/activation.rs","byte_start":5503,"byte_end":5504,"line_start":248,"line_end":248,"column_start":34,"column_end":35,"is_primary":true,"text":[{"text":"        let result = input * 0.5 * (&one + &tanh_val);","highlight_start":34,"highlight_end":35}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/activation.rs:248:34\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m248\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let result = input * 0.5 * (&one + &tanh_val);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/nn/activation.rs","byte_start":6560,"byte_end":6577,"line_start":300,"line_end":300,"column_start":37,"column_end":54,"is_primary":true,"text":[{"text":"        let sigmoid_output = &one / (&one + &exp_neg);","highlight_start":37,"highlight_end":54}],"label":"expected `&Tensor`, found `Tensor`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"consider dereferencing the borrow","code":null,"level":"help","spans":[{"file_name":"src/nn/activation.rs","byte_start":6553,"byte_end":6553,"line_start":300,"line_end":300,"column_start":30,"column_end":30,"is_primary":true,"text":[{"text":"        let sigmoid_output = &one / (&one + &exp_neg);","highlight_start":30,"highlight_end":30}],"label":null,"suggested_replacement":"*","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/activation.rs:300:37\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m300\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let sigmoid_output = &one / (&one + &exp_neg);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `Tensor`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider dereferencing the borrow\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m300\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m        let sigmoid_output = \u001b[0m\u001b[0m\u001b[38;5;10m*\u001b[0m\u001b[0m&one / (&one + &exp_neg);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[38;5;10m+\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot add `f32` to `tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/normalization.rs","byte_start":3039,"byte_end":3042,"line_start":96,"line_end":96,"column_start":46,"column_end":49,"is_primary":false,"text":[{"text":"        let normalized = (input - &mean) / &(var + self.eps).sqrt();","highlight_start":46,"highlight_end":49}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/normalization.rs","byte_start":3045,"byte_end":3053,"line_start":96,"line_end":96,"column_start":52,"column_end":60,"is_primary":false,"text":[{"text":"        let normalized = (input - &mean) / &(var + self.eps).sqrt();","highlight_start":52,"highlight_end":60}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/normalization.rs","byte_start":3043,"byte_end":3044,"line_start":96,"line_end":96,"column_start":50,"column_end":51,"is_primary":true,"text":[{"text":"        let normalized = (input - &mean) / &(var + self.eps).sqrt();","highlight_start":50,"highlight_end":51}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Add<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Add<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Add` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":2053,"byte_end":2078,"line_start":77,"line_end":77,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Add<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot add `f32` to `tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/normalization.rs:96:50\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m96\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let normalized = (input - &mean) / &(var + self.eps).sqrt();\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Add<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Add<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Add` must be implemented\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:77:1\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m77\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Add<Rhs = Self> {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"`(dyn nn::Module + 'static)` doesn't implement `std::fmt::Debug`","code":{"code":"E0277","explanation":"You tried to use a type which doesn't implement some trait in a place which\nexpected that trait.\n\nErroneous code example:\n\n```compile_fail,E0277\n// here we declare the Foo trait with a bar method\ntrait Foo {\n    fn bar(&self);\n}\n\n// we now declare a function which takes an object implementing the Foo trait\nfn some_func<T: Foo>(foo: T) {\n    foo.bar();\n}\n\nfn main() {\n    // we now call the method with the i32 type, which doesn't implement\n    // the Foo trait\n    some_func(5i32); // error: the trait bound `i32 : Foo` is not satisfied\n}\n```\n\nIn order to fix this error, verify that the type you're using does implement\nthe trait. Example:\n\n```\ntrait Foo {\n    fn bar(&self);\n}\n\n// we implement the trait on the i32 type\nimpl Foo for i32 {\n    fn bar(&self) {}\n}\n\nfn some_func<T: Foo>(foo: T) {\n    foo.bar(); // we can now use this method since i32 implements the\n               // Foo trait\n}\n\nfn main() {\n    some_func(5i32); // ok!\n}\n```\n\nOr in a generic context, an erroneous code example would look like:\n\n```compile_fail,E0277\nfn some_func<T>(foo: T) {\n    println!(\"{:?}\", foo); // error: the trait `core::fmt::Debug` is not\n                           //        implemented for the type `T`\n}\n\nfn main() {\n    // We now call the method with the i32 type,\n    // which *does* implement the Debug trait.\n    some_func(5i32);\n}\n```\n\nNote that the error here is in the definition of the generic function. Although\nwe only call it with a parameter that does implement `Debug`, the compiler\nstill rejects the function. It must work with all possible input types. In\norder to make this example compile, we need to restrict the generic type we're\naccepting:\n\n```\nuse std::fmt;\n\n// Restrict the input type to types that implement Debug.\nfn some_func<T: fmt::Debug>(foo: T) {\n    println!(\"{:?}\", foo);\n}\n\nfn main() {\n    // Calling the method is still fine, as i32 implements Debug.\n    some_func(5i32);\n\n    // This would fail to compile now:\n    // struct WithoutDebug;\n    // some_func(WithoutDebug);\n}\n```\n\nRust only looks at the signature of the called function, as such it must\nalready specify all requirements that will be used for every type parameter.\n"},"level":"error","spans":[{"file_name":"src/nn/mod.rs","byte_start":1683,"byte_end":1712,"line_start":61,"line_end":61,"column_start":5,"column_end":34,"is_primary":true,"text":[{"text":"    modules: Vec<Box<dyn Module>>,","highlight_start":5,"highlight_end":34}],"label":"`(dyn nn::Module + 'static)` cannot be formatted using `{:?}` because it doesn't implement `std::fmt::Debug`","suggested_replacement":null,"suggestion_applicability":null,"expansion":{"span":{"file_name":"src/nn/mod.rs","byte_start":1640,"byte_end":1645,"line_start":59,"line_end":59,"column_start":10,"column_end":15,"is_primary":false,"text":[{"text":"#[derive(Debug, Clone)]","highlight_start":10,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},"macro_decl_name":"#[derive(Debug)]","def_site_span":{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/fmt/mod.rs","byte_start":32468,"byte_end":32483,"line_start":901,"line_end":901,"column_start":5,"column_end":20,"is_primary":false,"text":[{"text":"    pub macro Debug($item:item) {","highlight_start":5,"highlight_end":20}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}}}],"children":[{"message":"the trait `std::fmt::Debug` is not implemented for `(dyn nn::Module + 'static)`","code":null,"level":"help","spans":[],"children":[],"rendered":null},{"message":"the following other types implement trait `std::fmt::Debug`:\n  dyn std::any::Any + Send + Sync\n  dyn std::any::Any + Send\n  dyn std::any::Any\n  dyn tracing::Value","code":null,"level":"help","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0277]\u001b[0m\u001b[0m\u001b[1m: `(dyn nn::Module + 'static)` doesn't implement `std::fmt::Debug`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:61:5\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m59\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m#[derive(Debug, Clone)]\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m          \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12min this derive macro expansion\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m60\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Sequential {\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m61\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    modules: Vec<Box<dyn Module>>,\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m`(dyn nn::Module + 'static)` cannot be formatted using `{:?}` because it doesn't implement `std::fmt::Debug`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mhelp\u001b[0m\u001b[0m: the trait `std::fmt::Debug` is not implemented for `(dyn nn::Module + 'static)`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mhelp\u001b[0m\u001b[0m: the following other types implement trait `std::fmt::Debug`:\u001b[0m\n\u001b[0m             dyn std::any::Any + Send + Sync\u001b[0m\n\u001b[0m             dyn std::any::Any + Send\u001b[0m\n\u001b[0m             dyn std::any::Any\u001b[0m\n\u001b[0m             dyn tracing::Value\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: this error originates in the derive macro `Debug` (in Nightly builds, run with -Z macro-backtrace for more info)\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"the trait bound `dyn nn::Module: Clone` is not satisfied","code":{"code":"E0277","explanation":"You tried to use a type which doesn't implement some trait in a place which\nexpected that trait.\n\nErroneous code example:\n\n```compile_fail,E0277\n// here we declare the Foo trait with a bar method\ntrait Foo {\n    fn bar(&self);\n}\n\n// we now declare a function which takes an object implementing the Foo trait\nfn some_func<T: Foo>(foo: T) {\n    foo.bar();\n}\n\nfn main() {\n    // we now call the method with the i32 type, which doesn't implement\n    // the Foo trait\n    some_func(5i32); // error: the trait bound `i32 : Foo` is not satisfied\n}\n```\n\nIn order to fix this error, verify that the type you're using does implement\nthe trait. Example:\n\n```\ntrait Foo {\n    fn bar(&self);\n}\n\n// we implement the trait on the i32 type\nimpl Foo for i32 {\n    fn bar(&self) {}\n}\n\nfn some_func<T: Foo>(foo: T) {\n    foo.bar(); // we can now use this method since i32 implements the\n               // Foo trait\n}\n\nfn main() {\n    some_func(5i32); // ok!\n}\n```\n\nOr in a generic context, an erroneous code example would look like:\n\n```compile_fail,E0277\nfn some_func<T>(foo: T) {\n    println!(\"{:?}\", foo); // error: the trait `core::fmt::Debug` is not\n                           //        implemented for the type `T`\n}\n\nfn main() {\n    // We now call the method with the i32 type,\n    // which *does* implement the Debug trait.\n    some_func(5i32);\n}\n```\n\nNote that the error here is in the definition of the generic function. Although\nwe only call it with a parameter that does implement `Debug`, the compiler\nstill rejects the function. It must work with all possible input types. In\norder to make this example compile, we need to restrict the generic type we're\naccepting:\n\n```\nuse std::fmt;\n\n// Restrict the input type to types that implement Debug.\nfn some_func<T: fmt::Debug>(foo: T) {\n    println!(\"{:?}\", foo);\n}\n\nfn main() {\n    // Calling the method is still fine, as i32 implements Debug.\n    some_func(5i32);\n\n    // This would fail to compile now:\n    // struct WithoutDebug;\n    // some_func(WithoutDebug);\n}\n```\n\nRust only looks at the signature of the called function, as such it must\nalready specify all requirements that will be used for every type parameter.\n"},"level":"error","spans":[{"file_name":"src/nn/mod.rs","byte_start":1683,"byte_end":1712,"line_start":61,"line_end":61,"column_start":5,"column_end":34,"is_primary":true,"text":[{"text":"    modules: Vec<Box<dyn Module>>,","highlight_start":5,"highlight_end":34}],"label":"the trait `Clone` is not implemented for `dyn nn::Module`","suggested_replacement":null,"suggestion_applicability":null,"expansion":{"span":{"file_name":"src/nn/mod.rs","byte_start":1647,"byte_end":1652,"line_start":59,"line_end":59,"column_start":17,"column_end":22,"is_primary":false,"text":[{"text":"#[derive(Debug, Clone)]","highlight_start":17,"highlight_end":22}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},"macro_decl_name":"#[derive(Clone)]","def_site_span":{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/clone.rs","byte_start":5958,"byte_end":5973,"line_start":183,"line_end":183,"column_start":1,"column_end":16,"is_primary":false,"text":[{"text":"pub macro Clone($item:item) {","highlight_start":1,"highlight_end":16}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}}}],"children":[{"message":"required for `Box<dyn nn::Module>` to implement `Clone`","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"1 redundant requirement hidden","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"required for `Vec<Box<dyn nn::Module>>` to implement `Clone`","code":null,"level":"note","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0277]\u001b[0m\u001b[0m\u001b[1m: the trait bound `dyn nn::Module: Clone` is not satisfied\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:61:5\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m59\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m#[derive(Debug, Clone)]\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12min this derive macro expansion\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m60\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Sequential {\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m61\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    modules: Vec<Box<dyn Module>>,\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mthe trait `Clone` is not implemented for `dyn nn::Module`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: required for `Box<dyn nn::Module>` to implement `Clone`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: 1 redundant requirement hidden\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: required for `Vec<Box<dyn nn::Module>>` to implement `Clone`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: this error originates in the derive macro `Clone` (in Nightly builds, run with -Z macro-backtrace for more info)\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/mod.rs","byte_start":4681,"byte_end":4708,"line_start":180,"line_end":180,"column_start":22,"column_end":49,"is_primary":false,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (2.0 * limit) - limit;","highlight_start":22,"highlight_end":49}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":4711,"byte_end":4724,"line_start":180,"line_end":180,"column_start":52,"column_end":65,"is_primary":false,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (2.0 * limit) - limit;","highlight_start":52,"highlight_end":65}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":4709,"byte_end":4710,"line_start":180,"line_end":180,"column_start":50,"column_end":51,"is_primary":true,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (2.0 * limit) - limit;","highlight_start":50,"highlight_end":51}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:180:50\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m180\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            *param = Tensor::rand(param.shape()) * (2.0 * limit) - limit;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/mod.rs","byte_start":4865,"byte_end":4893,"line_start":184,"line_end":184,"column_start":22,"column_end":50,"is_primary":false,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std;","highlight_start":22,"highlight_end":50}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":4896,"byte_end":4899,"line_start":184,"line_end":184,"column_start":53,"column_end":56,"is_primary":false,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std;","highlight_start":53,"highlight_end":56}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":4894,"byte_end":4895,"line_start":184,"line_end":184,"column_start":51,"column_end":52,"is_primary":true,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std;","highlight_start":51,"highlight_end":52}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:184:51\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m184\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            *param = Tensor::randn(param.shape()) * std;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/mod.rs","byte_start":5024,"byte_end":5051,"line_start":188,"line_end":188,"column_start":22,"column_end":49,"is_primary":false,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (2.0 * limit) - limit;","highlight_start":22,"highlight_end":49}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":5054,"byte_end":5067,"line_start":188,"line_end":188,"column_start":52,"column_end":65,"is_primary":false,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (2.0 * limit) - limit;","highlight_start":52,"highlight_end":65}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":5052,"byte_end":5053,"line_start":188,"line_end":188,"column_start":50,"column_end":51,"is_primary":true,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (2.0 * limit) - limit;","highlight_start":50,"highlight_end":51}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:188:50\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m188\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            *param = Tensor::rand(param.shape()) * (2.0 * limit) - limit;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/mod.rs","byte_start":5197,"byte_end":5225,"line_start":192,"line_end":192,"column_start":22,"column_end":50,"is_primary":false,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std;","highlight_start":22,"highlight_end":50}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":5228,"byte_end":5231,"line_start":192,"line_end":192,"column_start":53,"column_end":56,"is_primary":false,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std;","highlight_start":53,"highlight_end":56}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":5226,"byte_end":5227,"line_start":192,"line_end":192,"column_start":51,"column_end":52,"is_primary":true,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std;","highlight_start":51,"highlight_end":52}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:192:51\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m192\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            *param = Tensor::randn(param.shape()) * std;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/mod.rs","byte_start":5501,"byte_end":5528,"line_start":201,"line_end":201,"column_start":22,"column_end":49,"is_primary":false,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (high - low) + low;","highlight_start":22,"highlight_end":49}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":5531,"byte_end":5543,"line_start":201,"line_end":201,"column_start":52,"column_end":64,"is_primary":false,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (high - low) + low;","highlight_start":52,"highlight_end":64}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":5529,"byte_end":5530,"line_start":201,"line_end":201,"column_start":50,"column_end":51,"is_primary":true,"text":[{"text":"            *param = Tensor::rand(param.shape()) * (high - low) + low;","highlight_start":50,"highlight_end":51}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:201:50\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m201\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            *param = Tensor::rand(param.shape()) * (high - low) + low;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/nn/mod.rs","byte_start":5623,"byte_end":5651,"line_start":204,"line_end":204,"column_start":22,"column_end":50,"is_primary":false,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std + mean;","highlight_start":22,"highlight_end":50}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":5654,"byte_end":5657,"line_start":204,"line_end":204,"column_start":53,"column_end":56,"is_primary":false,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std + mean;","highlight_start":53,"highlight_end":56}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/nn/mod.rs","byte_start":5652,"byte_end":5653,"line_start":204,"line_end":204,"column_start":51,"column_end":52,"is_primary":true,"text":[{"text":"            *param = Tensor::randn(param.shape()) * std + mean;","highlight_start":51,"highlight_end":52}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/nn/mod.rs:204:51\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m204\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            *param = Tensor::randn(param.shape()) * std + mean;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/sgd.rs","byte_start":2202,"byte_end":2207,"line_start":84,"line_end":84,"column_start":40,"column_end":45,"is_primary":false,"text":[{"text":"                        d_p = &d_p + &(param * self.weight_decay);","highlight_start":40,"highlight_end":45}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/sgd.rs","byte_start":2210,"byte_end":2227,"line_start":84,"line_end":84,"column_start":48,"column_end":65,"is_primary":false,"text":[{"text":"                        d_p = &d_p + &(param * self.weight_decay);","highlight_start":48,"highlight_end":65}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/sgd.rs","byte_start":2208,"byte_end":2209,"line_start":84,"line_end":84,"column_start":46,"column_end":47,"is_primary":true,"text":[{"text":"                        d_p = &d_p + &(param * self.weight_decay);","highlight_start":46,"highlight_end":47}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/sgd.rs:84:46\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m84\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        d_p = &d_p + &(param * self.weight_decay);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                        \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                        \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                        \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/sgd.rs","byte_start":2577,"byte_end":2581,"line_start":93,"line_end":93,"column_start":34,"column_end":38,"is_primary":false,"text":[{"text":"                        *buf = &(*buf * self.momentum) + &(&d_p * (1.0 - self.dampening));","highlight_start":34,"highlight_end":38}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/sgd.rs","byte_start":2584,"byte_end":2597,"line_start":93,"line_end":93,"column_start":41,"column_end":54,"is_primary":false,"text":[{"text":"                        *buf = &(*buf * self.momentum) + &(&d_p * (1.0 - self.dampening));","highlight_start":41,"highlight_end":54}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/sgd.rs","byte_start":2582,"byte_end":2583,"line_start":93,"line_end":93,"column_start":39,"column_end":40,"is_primary":true,"text":[{"text":"                        *buf = &(*buf * self.momentum) + &(&d_p * (1.0 - self.dampening));","highlight_start":39,"highlight_end":40}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/sgd.rs:93:39\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m93\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *buf = &(*buf * self.momentum) + &(&d_p * (1.0 - self.dampening));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/sgd.rs","byte_start":2610,"byte_end":2632,"line_start":93,"line_end":93,"column_start":67,"column_end":89,"is_primary":true,"text":[{"text":"                        *buf = &(*buf * self.momentum) + &(&d_p * (1.0 - self.dampening));","highlight_start":67,"highlight_end":89}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/sgd.rs:93:67\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m93\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *buf = &(*buf * self.momentum) + &(&d_p * (1.0 - self.dampening));\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                                   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/sgd.rs","byte_start":2746,"byte_end":2749,"line_start":96,"line_end":96,"column_start":44,"column_end":47,"is_primary":false,"text":[{"text":"                            d_p = &d_p + &(buf * self.momentum);","highlight_start":44,"highlight_end":47}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/sgd.rs","byte_start":2752,"byte_end":2765,"line_start":96,"line_end":96,"column_start":50,"column_end":63,"is_primary":false,"text":[{"text":"                            d_p = &d_p + &(buf * self.momentum);","highlight_start":50,"highlight_end":63}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/sgd.rs","byte_start":2750,"byte_end":2751,"line_start":96,"line_end":96,"column_start":48,"column_end":49,"is_primary":true,"text":[{"text":"                            d_p = &d_p + &(buf * self.momentum);","highlight_start":48,"highlight_end":49}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/sgd.rs:96:48\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m96\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m...\u001b[0m\u001b[0m                   d_p = &d_p + &(buf * self.momentum);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/sgd.rs","byte_start":3011,"byte_end":3018,"line_start":103,"line_end":103,"column_start":47,"column_end":54,"is_primary":true,"text":[{"text":"                    *param = param - &(&d_p * self.lr);","highlight_start":47,"highlight_end":54}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/sgd.rs:103:47\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m103\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *param = param - &(&d_p * self.lr);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                               \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot subtract `&tensor::Tensor` from `&mut tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/sgd.rs","byte_start":2994,"byte_end":2999,"line_start":103,"line_end":103,"column_start":30,"column_end":35,"is_primary":false,"text":[{"text":"                    *param = param - &(&d_p * self.lr);","highlight_start":30,"highlight_end":35}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/sgd.rs","byte_start":3002,"byte_end":3019,"line_start":103,"line_end":103,"column_start":38,"column_end":55,"is_primary":false,"text":[{"text":"                    *param = param - &(&d_p * self.lr);","highlight_start":38,"highlight_end":55}],"label":"&tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/sgd.rs","byte_start":3000,"byte_end":3001,"line_start":103,"line_end":103,"column_start":36,"column_end":37,"is_primary":true,"text":[{"text":"                    *param = param - &(&d_p * self.lr);","highlight_start":36,"highlight_end":37}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation for `&tensor::Tensor - &tensor::Tensor` exists","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"consider reborrowing this side","code":null,"level":"help","spans":[{"file_name":"src/optim/sgd.rs","byte_start":2994,"byte_end":2994,"line_start":103,"line_end":103,"column_start":30,"column_end":30,"is_primary":true,"text":[{"text":"                    *param = param - &(&d_p * self.lr);","highlight_start":30,"highlight_end":30}],"label":null,"suggested_replacement":"&*","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot subtract `&tensor::Tensor` from `&mut tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/sgd.rs:103:36\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m103\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *param = param - &(&d_p * self.lr);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&tensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: an implementation for `&tensor::Tensor - &tensor::Tensor` exists\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider reborrowing this side\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m103\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m                    *param = \u001b[0m\u001b[0m\u001b[38;5;10m&*\u001b[0m\u001b[0mparam - &(&d_p * self.lr);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[38;5;10m++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":2878,"byte_end":2883,"line_start":106,"line_end":106,"column_start":52,"column_end":57,"is_primary":false,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":52,"highlight_end":57}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":2886,"byte_end":2903,"line_start":106,"line_end":106,"column_start":60,"column_end":77,"is_primary":false,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":60,"highlight_end":77}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":2884,"byte_end":2885,"line_start":106,"line_end":106,"column_start":58,"column_end":59,"is_primary":true,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":58,"highlight_end":59}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:106:58\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m106\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        grad_data = &grad_data + &(param * self.weight_decay);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":3418,"byte_end":3420,"line_start":118,"line_end":118,"column_start":28,"column_end":30,"is_primary":false,"text":[{"text":"                    *m = &(*m * self.beta1) + &(&grad_data * (1.0 - self.beta1));","highlight_start":28,"highlight_end":30}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":3423,"byte_end":3433,"line_start":118,"line_end":118,"column_start":33,"column_end":43,"is_primary":false,"text":[{"text":"                    *m = &(*m * self.beta1) + &(&grad_data * (1.0 - self.beta1));","highlight_start":33,"highlight_end":43}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":3421,"byte_end":3422,"line_start":118,"line_end":118,"column_start":31,"column_end":32,"is_primary":true,"text":[{"text":"                    *m = &(*m * self.beta1) + &(&grad_data * (1.0 - self.beta1));","highlight_start":31,"highlight_end":32}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:118:31\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m118\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *m = &(*m * self.beta1) + &(&grad_data * (1.0 - self.beta1));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":3452,"byte_end":3470,"line_start":118,"line_end":118,"column_start":62,"column_end":80,"is_primary":true,"text":[{"text":"                    *m = &(*m * self.beta1) + &(&grad_data * (1.0 - self.beta1));","highlight_start":62,"highlight_end":80}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:118:62\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m118\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *m = &(*m * self.beta1) + &(&grad_data * (1.0 - self.beta1));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":3649,"byte_end":3651,"line_start":122,"line_end":122,"column_start":28,"column_end":30,"is_primary":false,"text":[{"text":"                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));","highlight_start":28,"highlight_end":30}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":3654,"byte_end":3664,"line_start":122,"line_end":122,"column_start":33,"column_end":43,"is_primary":false,"text":[{"text":"                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));","highlight_start":33,"highlight_end":43}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":3652,"byte_end":3653,"line_start":122,"line_end":122,"column_start":31,"column_end":32,"is_primary":true,"text":[{"text":"                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));","highlight_start":31,"highlight_end":32}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:122:31\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m122\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":3686,"byte_end":3704,"line_start":122,"line_end":122,"column_start":65,"column_end":83,"is_primary":true,"text":[{"text":"                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));","highlight_start":65,"highlight_end":83}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:122:65\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m122\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":4029,"byte_end":4030,"line_start":128,"line_end":128,"column_start":33,"column_end":34,"is_primary":false,"text":[{"text":"                    let m_hat = m * (1.0 / bias_correction1);","highlight_start":33,"highlight_end":34}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":4033,"byte_end":4057,"line_start":128,"line_end":128,"column_start":37,"column_end":61,"is_primary":false,"text":[{"text":"                    let m_hat = m * (1.0 / bias_correction1);","highlight_start":37,"highlight_end":61}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":4031,"byte_end":4032,"line_start":128,"line_end":128,"column_start":35,"column_end":36,"is_primary":true,"text":[{"text":"                    let m_hat = m * (1.0 / bias_correction1);","highlight_start":35,"highlight_end":36}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:128:35\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m128\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    let m_hat = m * (1.0 / bias_correction1);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":4091,"byte_end":4092,"line_start":129,"line_end":129,"column_start":33,"column_end":34,"is_primary":false,"text":[{"text":"                    let v_hat = v * (1.0 / bias_correction2);","highlight_start":33,"highlight_end":34}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":4095,"byte_end":4119,"line_start":129,"line_end":129,"column_start":37,"column_end":61,"is_primary":false,"text":[{"text":"                    let v_hat = v * (1.0 / bias_correction2);","highlight_start":37,"highlight_end":61}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":4093,"byte_end":4094,"line_start":129,"line_end":129,"column_start":35,"column_end":36,"is_primary":true,"text":[{"text":"                    let v_hat = v * (1.0 / bias_correction2);","highlight_start":35,"highlight_end":36}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:129:35\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m129\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    let v_hat = v * (1.0 / bias_correction2);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot add `f32` to `tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":4819,"byte_end":4831,"line_start":143,"line_end":143,"column_start":25,"column_end":37,"is_primary":false,"text":[{"text":"                        v_max.sqrt() + self.eps","highlight_start":25,"highlight_end":37}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":4834,"byte_end":4842,"line_start":143,"line_end":143,"column_start":40,"column_end":48,"is_primary":false,"text":[{"text":"                        v_max.sqrt() + self.eps","highlight_start":40,"highlight_end":48}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":4832,"byte_end":4833,"line_start":143,"line_end":143,"column_start":38,"column_end":39,"is_primary":true,"text":[{"text":"                        v_max.sqrt() + self.eps","highlight_start":38,"highlight_end":39}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Add<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Add<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Add` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":2053,"byte_end":2078,"line_start":77,"line_end":77,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Add<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot add `f32` to `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:143:38\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m143\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        v_max.sqrt() + self.eps\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Add<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Add<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Add` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:77:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m77\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Add<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/adam.rs","byte_start":5090,"byte_end":5118,"line_start":150,"line_end":150,"column_start":30,"column_end":58,"is_primary":true,"text":[{"text":"                    *param = param - &(&update * self.lr);","highlight_start":30,"highlight_end":58}],"label":"expected `Tensor`, found `&mut Tensor`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adam.rs","byte_start":5081,"byte_end":5087,"line_start":150,"line_end":150,"column_start":21,"column_end":27,"is_primary":false,"text":[{"text":"                    *param = param - &(&update * self.lr);","highlight_start":21,"highlight_end":27}],"label":"expected due to the type of this binding","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adam.rs:150:30\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m150\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *param = param - &(&update * self.lr);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------\u001b[0m\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `Tensor`, found `&mut Tensor`\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mexpected due to the type of this binding\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adamw.rs","byte_start":1745,"byte_end":1750,"line_start":64,"line_end":64,"column_start":34,"column_end":39,"is_primary":false,"text":[{"text":"                        *param = param * (1.0 - self.lr * self.weight_decay);","highlight_start":34,"highlight_end":39}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":1753,"byte_end":1788,"line_start":64,"line_end":64,"column_start":42,"column_end":77,"is_primary":false,"text":[{"text":"                        *param = param * (1.0 - self.lr * self.weight_decay);","highlight_start":42,"highlight_end":77}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":1751,"byte_end":1752,"line_start":64,"line_end":64,"column_start":40,"column_end":41,"is_primary":true,"text":[{"text":"                        *param = param * (1.0 - self.lr * self.weight_decay);","highlight_start":40,"highlight_end":41}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adamw.rs:64:40\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m64\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *param = param * (1.0 - self.lr * self.weight_decay);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adamw.rs","byte_start":2302,"byte_end":2304,"line_start":76,"line_end":76,"column_start":28,"column_end":30,"is_primary":false,"text":[{"text":"                    *m = &(*m * self.beta1) + &(grad * (1.0 - self.beta1));","highlight_start":28,"highlight_end":30}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":2307,"byte_end":2317,"line_start":76,"line_end":76,"column_start":33,"column_end":43,"is_primary":false,"text":[{"text":"                    *m = &(*m * self.beta1) + &(grad * (1.0 - self.beta1));","highlight_start":33,"highlight_end":43}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":2305,"byte_end":2306,"line_start":76,"line_end":76,"column_start":31,"column_end":32,"is_primary":true,"text":[{"text":"                    *m = &(*m * self.beta1) + &(grad * (1.0 - self.beta1));","highlight_start":31,"highlight_end":32}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adamw.rs:76:31\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m76\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *m = &(*m * self.beta1) + &(grad * (1.0 - self.beta1));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/adamw.rs","byte_start":2330,"byte_end":2348,"line_start":76,"line_end":76,"column_start":56,"column_end":74,"is_primary":true,"text":[{"text":"                    *m = &(*m * self.beta1) + &(grad * (1.0 - self.beta1));","highlight_start":56,"highlight_end":74}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adamw.rs:76:56\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m76\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *m = &(*m * self.beta1) + &(grad * (1.0 - self.beta1));\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                        \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adamw.rs","byte_start":2515,"byte_end":2517,"line_start":80,"line_end":80,"column_start":28,"column_end":30,"is_primary":false,"text":[{"text":"                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));","highlight_start":28,"highlight_end":30}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":2520,"byte_end":2530,"line_start":80,"line_end":80,"column_start":33,"column_end":43,"is_primary":false,"text":[{"text":"                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));","highlight_start":33,"highlight_end":43}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":2518,"byte_end":2519,"line_start":80,"line_end":80,"column_start":31,"column_end":32,"is_primary":true,"text":[{"text":"                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));","highlight_start":31,"highlight_end":32}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adamw.rs:80:31\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m80\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/adamw.rs","byte_start":2552,"byte_end":2570,"line_start":80,"line_end":80,"column_start":65,"column_end":83,"is_primary":true,"text":[{"text":"                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));","highlight_start":65,"highlight_end":83}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adamw.rs:80:65\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m80\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *v = &(*v * self.beta2) + &(&grad_squared * (1.0 - self.beta2));\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adamw.rs","byte_start":2895,"byte_end":2896,"line_start":86,"line_end":86,"column_start":33,"column_end":34,"is_primary":false,"text":[{"text":"                    let m_hat = m * (1.0 / bias_correction1);","highlight_start":33,"highlight_end":34}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":2899,"byte_end":2923,"line_start":86,"line_end":86,"column_start":37,"column_end":61,"is_primary":false,"text":[{"text":"                    let m_hat = m * (1.0 / bias_correction1);","highlight_start":37,"highlight_end":61}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":2897,"byte_end":2898,"line_start":86,"line_end":86,"column_start":35,"column_end":36,"is_primary":true,"text":[{"text":"                    let m_hat = m * (1.0 / bias_correction1);","highlight_start":35,"highlight_end":36}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adamw.rs:86:35\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m86\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    let m_hat = m * (1.0 / bias_correction1);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adamw.rs","byte_start":2957,"byte_end":2958,"line_start":87,"line_end":87,"column_start":33,"column_end":34,"is_primary":false,"text":[{"text":"                    let v_hat = v * (1.0 / bias_correction2);","highlight_start":33,"highlight_end":34}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":2961,"byte_end":2985,"line_start":87,"line_end":87,"column_start":37,"column_end":61,"is_primary":false,"text":[{"text":"                    let v_hat = v * (1.0 / bias_correction2);","highlight_start":37,"highlight_end":61}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":2959,"byte_end":2960,"line_start":87,"line_end":87,"column_start":35,"column_end":36,"is_primary":true,"text":[{"text":"                    let v_hat = v * (1.0 / bias_correction2);","highlight_start":35,"highlight_end":36}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adamw.rs:87:35\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m87\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    let v_hat = v * (1.0 / bias_correction2);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                 \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/adamw.rs","byte_start":3197,"byte_end":3225,"line_start":92,"line_end":92,"column_start":30,"column_end":58,"is_primary":true,"text":[{"text":"                    *param = param - &(&update * self.lr);","highlight_start":30,"highlight_end":58}],"label":"expected `Tensor`, found `&mut Tensor`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adamw.rs","byte_start":3188,"byte_end":3194,"line_start":92,"line_end":92,"column_start":21,"column_end":27,"is_primary":false,"text":[{"text":"                    *param = param - &(&update * self.lr);","highlight_start":21,"highlight_end":27}],"label":"expected due to the type of this binding","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adamw.rs:92:30\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m92\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *param = param - &(&update * self.lr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------\u001b[0m\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `Tensor`, found `&mut Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mexpected due to the type of this binding\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":1285,"byte_end":1290,"line_start":48,"line_end":48,"column_start":52,"column_end":57,"is_primary":false,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":52,"highlight_end":57}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":1293,"byte_end":1310,"line_start":48,"line_end":48,"column_start":60,"column_end":77,"is_primary":false,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":60,"highlight_end":77}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":1291,"byte_end":1292,"line_start":48,"line_end":48,"column_start":58,"column_end":59,"is_primary":true,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":58,"highlight_end":59}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:48:58\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m48\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        grad_data = &grad_data + &(param * self.weight_decay);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":1572,"byte_end":1583,"line_start":55,"line_end":55,"column_start":37,"column_end":48,"is_primary":false,"text":[{"text":"                    *square_avg = &(*square_avg * self.alpha) + &(&(&grad_data * &grad_data) * (1.0 - self.alpha));","highlight_start":37,"highlight_end":48}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":1586,"byte_end":1596,"line_start":55,"line_end":55,"column_start":51,"column_end":61,"is_primary":false,"text":[{"text":"                    *square_avg = &(*square_avg * self.alpha) + &(&(&grad_data * &grad_data) * (1.0 - self.alpha));","highlight_start":51,"highlight_end":61}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":1584,"byte_end":1585,"line_start":55,"line_end":55,"column_start":49,"column_end":50,"is_primary":true,"text":[{"text":"                    *square_avg = &(*square_avg * self.alpha) + &(&(&grad_data * &grad_data) * (1.0 - self.alpha));","highlight_start":49,"highlight_end":50}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:55:49\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m55\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *square_avg = &(*square_avg * self.alpha) + &(&(&grad_data * &grad_data) * (1.0 - self.alpha));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":1631,"byte_end":1649,"line_start":55,"line_end":55,"column_start":96,"column_end":114,"is_primary":true,"text":[{"text":"                    *square_avg = &(*square_avg * self.alpha) + &(&(&grad_data * &grad_data) * (1.0 - self.alpha));","highlight_start":96,"highlight_end":114}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:55:96\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m55\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *square_avg = &(*square_avg * self.alpha) + &(&(&grad_data * &grad_data) * (1.0 - self.alpha));\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                                                                \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":1927,"byte_end":1936,"line_start":61,"line_end":61,"column_start":39,"column_end":48,"is_primary":false,"text":[{"text":"                        *grad_avg = &(*grad_avg * self.alpha) + &(&grad_data * (1.0 - self.alpha));","highlight_start":39,"highlight_end":48}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":1939,"byte_end":1949,"line_start":61,"line_end":61,"column_start":51,"column_end":61,"is_primary":false,"text":[{"text":"                        *grad_avg = &(*grad_avg * self.alpha) + &(&grad_data * (1.0 - self.alpha));","highlight_start":51,"highlight_end":61}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":1937,"byte_end":1938,"line_start":61,"line_end":61,"column_start":49,"column_end":50,"is_primary":true,"text":[{"text":"                        *grad_avg = &(*grad_avg * self.alpha) + &(&grad_data * (1.0 - self.alpha));","highlight_start":49,"highlight_end":50}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:61:49\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m61\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *grad_avg = &(*grad_avg * self.alpha) + &(&grad_data * (1.0 - self.alpha));\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                       \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                       \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                       \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":1968,"byte_end":1986,"line_start":61,"line_end":61,"column_start":80,"column_end":98,"is_primary":true,"text":[{"text":"                        *grad_avg = &(*grad_avg * self.alpha) + &(&grad_data * (1.0 - self.alpha));","highlight_start":80,"highlight_end":98}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:61:80\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m61\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *grad_avg = &(*grad_avg * self.alpha) + &(&grad_data * (1.0 - self.alpha));\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                                                \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `&mut tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2072,"byte_end":2080,"line_start":63,"line_end":63,"column_start":59,"column_end":67,"is_primary":false,"text":[{"text":"                        let centered_var = square_avg - &(grad_avg * grad_avg);","highlight_start":59,"highlight_end":67}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2083,"byte_end":2091,"line_start":63,"line_end":63,"column_start":70,"column_end":78,"is_primary":false,"text":[{"text":"                        let centered_var = square_avg - &(grad_avg * grad_avg);","highlight_start":70,"highlight_end":78}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2081,"byte_end":2082,"line_start":63,"line_end":63,"column_start":68,"column_end":69,"is_primary":true,"text":[{"text":"                        let centered_var = square_avg - &(grad_avg * grad_avg);","highlight_start":68,"highlight_end":69}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation for `&tensor::Tensor * &tensor::Tensor` exists","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"consider reborrowing both sides","code":null,"level":"help","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2072,"byte_end":2072,"line_start":63,"line_end":63,"column_start":59,"column_end":59,"is_primary":true,"text":[{"text":"                        let centered_var = square_avg - &(grad_avg * grad_avg);","highlight_start":59,"highlight_end":59}],"label":null,"suggested_replacement":"&*","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2083,"byte_end":2083,"line_start":63,"line_end":63,"column_start":70,"column_end":70,"is_primary":true,"text":[{"text":"                        let centered_var = square_avg - &(grad_avg * grad_avg);","highlight_start":70,"highlight_end":70}],"label":null,"suggested_replacement":"&*","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `&mut tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:63:68\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m63\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        let centered_var = square_avg - &(grad_avg * grad_avg);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: an implementation for `&tensor::Tensor * &tensor::Tensor` exists\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider reborrowing both sides\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m63\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m                        let centered_var = square_avg - &(\u001b[0m\u001b[0m\u001b[38;5;10m&*\u001b[0m\u001b[0mgrad_avg * \u001b[0m\u001b[0m\u001b[38;5;10m&*\u001b[0m\u001b[0mgrad_avg);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                           \u001b[0m\u001b[0m\u001b[38;5;10m++\u001b[0m\u001b[0m           \u001b[0m\u001b[0m\u001b[38;5;10m++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot add `f32` to `&mut tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2119,"byte_end":2131,"line_start":64,"line_end":64,"column_start":26,"column_end":38,"is_primary":false,"text":[{"text":"                        (centered_var + self.eps).sqrt()","highlight_start":26,"highlight_end":38}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2134,"byte_end":2142,"line_start":64,"line_end":64,"column_start":41,"column_end":49,"is_primary":false,"text":[{"text":"                        (centered_var + self.eps).sqrt()","highlight_start":41,"highlight_end":49}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2132,"byte_end":2133,"line_start":64,"line_end":64,"column_start":39,"column_end":40,"is_primary":true,"text":[{"text":"                        (centered_var + self.eps).sqrt()","highlight_start":39,"highlight_end":40}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot add `f32` to `&mut tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:64:39\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m64\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        (centered_var + self.eps).sqrt()\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                          \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                          \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                          \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot add `f32` to `&mut tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2205,"byte_end":2215,"line_start":66,"line_end":66,"column_start":26,"column_end":36,"is_primary":false,"text":[{"text":"                        (square_avg + self.eps).sqrt()","highlight_start":26,"highlight_end":36}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2218,"byte_end":2226,"line_start":66,"line_end":66,"column_start":39,"column_end":47,"is_primary":false,"text":[{"text":"                        (square_avg + self.eps).sqrt()","highlight_start":39,"highlight_end":47}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2216,"byte_end":2217,"line_start":66,"line_end":66,"column_start":37,"column_end":38,"is_primary":true,"text":[{"text":"                        (square_avg + self.eps).sqrt()","highlight_start":37,"highlight_end":38}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot add `f32` to `&mut tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:66:37\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m66\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        (square_avg + self.eps).sqrt()\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                          \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                          \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                          \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2526,"byte_end":2530,"line_start":73,"line_end":73,"column_start":34,"column_end":38,"is_primary":false,"text":[{"text":"                        *buf = &(*buf * self.momentum) + &(&grad_data / &avg);","highlight_start":34,"highlight_end":38}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2533,"byte_end":2546,"line_start":73,"line_end":73,"column_start":41,"column_end":54,"is_primary":false,"text":[{"text":"                        *buf = &(*buf * self.momentum) + &(&grad_data / &avg);","highlight_start":41,"highlight_end":54}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2531,"byte_end":2532,"line_start":73,"line_end":73,"column_start":39,"column_end":40,"is_primary":true,"text":[{"text":"                        *buf = &(*buf * self.momentum) + &(&grad_data / &avg);","highlight_start":39,"highlight_end":40}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Mul<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Mul<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Mul` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":8844,"byte_end":8869,"line_start":328,"line_end":328,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Mul<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:73:39\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m73\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *buf = &(*buf * self.momentum) + &(&grad_data / &avg);\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Mul<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Mul<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Mul` must be implemented\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:328:1\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m328\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Mul<Rhs = Self> {\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2615,"byte_end":2618,"line_start":74,"line_end":74,"column_start":44,"column_end":47,"is_primary":false,"text":[{"text":"                        *param = param - &(buf * self.lr);","highlight_start":44,"highlight_end":47}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2621,"byte_end":2628,"line_start":74,"line_end":74,"column_start":50,"column_end":57,"is_primary":false,"text":[{"text":"                        *param = param - &(buf * self.lr);","highlight_start":50,"highlight_end":57}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2619,"byte_end":2620,"line_start":74,"line_end":74,"column_start":48,"column_end":49,"is_primary":true,"text":[{"text":"                        *param = param - &(buf * self.lr);","highlight_start":48,"highlight_end":49}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:74:48\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m74\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *param = param - &(buf * self.lr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2605,"byte_end":2629,"line_start":74,"line_end":74,"column_start":34,"column_end":58,"is_primary":true,"text":[{"text":"                        *param = param - &(buf * self.lr);","highlight_start":34,"highlight_end":58}],"label":"expected `Tensor`, found `&mut Tensor`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2596,"byte_end":2602,"line_start":74,"line_end":74,"column_start":25,"column_end":31,"is_primary":false,"text":[{"text":"                        *param = param - &(buf * self.lr);","highlight_start":25,"highlight_end":31}],"label":"expected due to the type of this binding","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:74:34\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m74\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *param = param - &(buf * self.lr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------\u001b[0m\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `Tensor`, found `&mut Tensor`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mexpected due to the type of this binding\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2726,"byte_end":2733,"line_start":76,"line_end":76,"column_start":67,"column_end":74,"is_primary":true,"text":[{"text":"                        *param = param - &(&(&grad_data / &avg) * self.lr);","highlight_start":67,"highlight_end":74}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:76:67\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m76\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *param = param - &(&(&grad_data / &avg) * self.lr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                                   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot subtract `&tensor::Tensor` from `&mut tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2693,"byte_end":2698,"line_start":76,"line_end":76,"column_start":34,"column_end":39,"is_primary":false,"text":[{"text":"                        *param = param - &(&(&grad_data / &avg) * self.lr);","highlight_start":34,"highlight_end":39}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2701,"byte_end":2734,"line_start":76,"line_end":76,"column_start":42,"column_end":75,"is_primary":false,"text":[{"text":"                        *param = param - &(&(&grad_data / &avg) * self.lr);","highlight_start":42,"highlight_end":75}],"label":"&tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/rmsprop.rs","byte_start":2699,"byte_end":2700,"line_start":76,"line_end":76,"column_start":40,"column_end":41,"is_primary":true,"text":[{"text":"                        *param = param - &(&(&grad_data / &avg) * self.lr);","highlight_start":40,"highlight_end":41}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation for `&tensor::Tensor - &tensor::Tensor` exists","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"consider reborrowing this side","code":null,"level":"help","spans":[{"file_name":"src/optim/rmsprop.rs","byte_start":2693,"byte_end":2693,"line_start":76,"line_end":76,"column_start":34,"column_end":34,"is_primary":true,"text":[{"text":"                        *param = param - &(&(&grad_data / &avg) * self.lr);","highlight_start":34,"highlight_end":34}],"label":null,"suggested_replacement":"&*","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot subtract `&tensor::Tensor` from `&mut tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/rmsprop.rs:76:40\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m76\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        *param = param - &(&(&grad_data / &avg) * self.lr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m---------------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&tensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: an implementation for `&tensor::Tensor - &tensor::Tensor` exists\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider reborrowing this side\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m76\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m                        *param = \u001b[0m\u001b[0m\u001b[38;5;10m&*\u001b[0m\u001b[0mparam - &(&(&grad_data / &avg) * self.lr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                  \u001b[0m\u001b[0m\u001b[38;5;10m++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot multiply `&mut tensor::Tensor` by `f32`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adagrad.rs","byte_start":1205,"byte_end":1210,"line_start":45,"line_end":45,"column_start":52,"column_end":57,"is_primary":false,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":52,"highlight_end":57}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adagrad.rs","byte_start":1213,"byte_end":1230,"line_start":45,"line_end":45,"column_start":60,"column_end":77,"is_primary":false,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":60,"highlight_end":77}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adagrad.rs","byte_start":1211,"byte_end":1212,"line_start":45,"line_end":45,"column_start":58,"column_end":59,"is_primary":true,"text":[{"text":"                        grad_data = &grad_data + &(param * self.weight_decay);","highlight_start":58,"highlight_end":59}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot multiply `&mut tensor::Tensor` by `f32`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adagrad.rs:45:58\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m45\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                        grad_data = &grad_data + &(param * self.weight_decay);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot add `&tensor::Tensor` to `&mut tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adagrad.rs","byte_start":1483,"byte_end":1489,"line_start":52,"line_end":52,"column_start":31,"column_end":37,"is_primary":false,"text":[{"text":"                    *sum_sq = sum_sq + &(&grad_data * &grad_data);","highlight_start":31,"highlight_end":37}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adagrad.rs","byte_start":1492,"byte_end":1518,"line_start":52,"line_end":52,"column_start":40,"column_end":66,"is_primary":false,"text":[{"text":"                    *sum_sq = sum_sq + &(&grad_data * &grad_data);","highlight_start":40,"highlight_end":66}],"label":"&tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adagrad.rs","byte_start":1490,"byte_end":1491,"line_start":52,"line_end":52,"column_start":38,"column_end":39,"is_primary":true,"text":[{"text":"                    *sum_sq = sum_sq + &(&grad_data * &grad_data);","highlight_start":38,"highlight_end":39}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation for `&tensor::Tensor + &tensor::Tensor` exists","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"consider reborrowing this side","code":null,"level":"help","spans":[{"file_name":"src/optim/adagrad.rs","byte_start":1483,"byte_end":1483,"line_start":52,"line_end":52,"column_start":31,"column_end":31,"is_primary":true,"text":[{"text":"                    *sum_sq = sum_sq + &(&grad_data * &grad_data);","highlight_start":31,"highlight_end":31}],"label":null,"suggested_replacement":"&*","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot add `&tensor::Tensor` to `&mut tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adagrad.rs:52:38\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m52\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *sum_sq = sum_sq + &(&grad_data * &grad_data);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                               \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&tensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                               \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                               \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: an implementation for `&tensor::Tensor + &tensor::Tensor` exists\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider reborrowing this side\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m52\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m                    *sum_sq = \u001b[0m\u001b[0m\u001b[38;5;10m&*\u001b[0m\u001b[0msum_sq + &(&grad_data * &grad_data);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                               \u001b[0m\u001b[0m\u001b[38;5;10m++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot add `f32` to `tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adagrad.rs","byte_start":1550,"byte_end":1563,"line_start":53,"line_end":53,"column_start":31,"column_end":44,"is_primary":false,"text":[{"text":"                    let std = sum_sq.sqrt() + self.eps;","highlight_start":31,"highlight_end":44}],"label":"tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adagrad.rs","byte_start":1566,"byte_end":1574,"line_start":53,"line_end":53,"column_start":47,"column_end":55,"is_primary":false,"text":[{"text":"                    let std = sum_sq.sqrt() + self.eps;","highlight_start":47,"highlight_end":55}],"label":"f32","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adagrad.rs","byte_start":1564,"byte_end":1565,"line_start":53,"line_end":53,"column_start":45,"column_end":46,"is_primary":true,"text":[{"text":"                    let std = sum_sq.sqrt() + self.eps;","highlight_start":45,"highlight_end":46}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation of `Add<f32>` might be missing for `tensor::Tensor`","code":null,"level":"note","spans":[{"file_name":"src/tensor.rs","byte_start":1097,"byte_end":1114,"line_start":42,"line_end":42,"column_start":1,"column_end":18,"is_primary":true,"text":[{"text":"pub struct Tensor {","highlight_start":1,"highlight_end":18}],"label":"must implement `Add<f32>`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null},{"message":"the trait `Add` must be implemented","code":null,"level":"note","spans":[{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs","byte_start":2053,"byte_end":2078,"line_start":77,"line_end":77,"column_start":1,"column_end":26,"is_primary":true,"text":[{"text":"pub trait Add<Rhs = Self> {","highlight_start":1,"highlight_end":26}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot add `f32` to `tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adagrad.rs:53:45\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m53\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    let std = sum_sq.sqrt() + self.eps;\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                               \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mf32\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                               \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                               \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12mtensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: an implementation of `Add<f32>` might be missing for `tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/tensor.rs:42:1\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m42\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub struct Tensor {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10mmust implement `Add<f32>`\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;10mnote\u001b[0m\u001b[0m: the trait `Add` must be implemented\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0m/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/ops/arith.rs:77:1\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m77\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mpub trait Add<Rhs = Self> {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;10m^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/optim/adagrad.rs","byte_start":1638,"byte_end":1641,"line_start":54,"line_end":54,"column_start":63,"column_end":66,"is_primary":true,"text":[{"text":"                    *param = param - &(&(&grad_data / &std) * clr);","highlight_start":63,"highlight_end":66}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adagrad.rs:54:63\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m54\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *param = param - &(&(&grad_data / &std) * clr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                               \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"cannot subtract `&tensor::Tensor` from `&mut tensor::Tensor`","code":{"code":"E0369","explanation":"A binary operation was attempted on a type which doesn't support it.\n\nErroneous code example:\n\n```compile_fail,E0369\nlet x = 12f32; // error: binary operation `<<` cannot be applied to\n               //        type `f32`\n\nx << 2;\n```\n\nTo fix this error, please check that this type implements this binary\noperation. Example:\n\n```\nlet x = 12u32; // the `u32` type does implement it:\n               // https://doc.rust-lang.org/stable/std/ops/trait.Shl.html\n\nx << 2; // ok!\n```\n\nIt is also possible to overload most operators for your own type by\nimplementing traits from `std::ops`.\n\nString concatenation appends the string on the right to the string on the\nleft and may require reallocation. This requires ownership of the string\non the left. If something should be added to a string literal, move the\nliteral to the heap by allocating it with `to_owned()` like in\n`\"Your text\".to_owned()`.\n"},"level":"error","spans":[{"file_name":"src/optim/adagrad.rs","byte_start":1605,"byte_end":1610,"line_start":54,"line_end":54,"column_start":30,"column_end":35,"is_primary":false,"text":[{"text":"                    *param = param - &(&(&grad_data / &std) * clr);","highlight_start":30,"highlight_end":35}],"label":"&mut tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adagrad.rs","byte_start":1613,"byte_end":1642,"line_start":54,"line_end":54,"column_start":38,"column_end":67,"is_primary":false,"text":[{"text":"                    *param = param - &(&(&grad_data / &std) * clr);","highlight_start":38,"highlight_end":67}],"label":"&tensor::Tensor","suggested_replacement":null,"suggestion_applicability":null,"expansion":null},{"file_name":"src/optim/adagrad.rs","byte_start":1611,"byte_end":1612,"line_start":54,"line_end":54,"column_start":36,"column_end":37,"is_primary":true,"text":[{"text":"                    *param = param - &(&(&grad_data / &std) * clr);","highlight_start":36,"highlight_end":37}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"an implementation for `&tensor::Tensor - &tensor::Tensor` exists","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"consider reborrowing this side","code":null,"level":"help","spans":[{"file_name":"src/optim/adagrad.rs","byte_start":1605,"byte_end":1605,"line_start":54,"line_end":54,"column_start":30,"column_end":30,"is_primary":true,"text":[{"text":"                    *param = param - &(&(&grad_data / &std) * clr);","highlight_start":30,"highlight_end":30}],"label":null,"suggested_replacement":"&*","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0369]\u001b[0m\u001b[0m\u001b[1m: cannot subtract `&tensor::Tensor` from `&mut tensor::Tensor`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/optim/adagrad.rs:54:36\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m54\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                    *param = param - &(&(&grad_data / &std) * clr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----------------------------\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&tensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m&mut tensor::Tensor\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: an implementation for `&tensor::Tensor - &tensor::Tensor` exists\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14mhelp\u001b[0m\u001b[0m: consider reborrowing this side\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m54\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m| \u001b[0m\u001b[0m                    *param = \u001b[0m\u001b[0m\u001b[38;5;10m&*\u001b[0m\u001b[0mparam - &(&(&grad_data / &std) * clr);\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                              \u001b[0m\u001b[0m\u001b[38;5;10m++\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/loss/mod.rs","byte_start":1223,"byte_end":1226,"line_start":44,"line_end":44,"column_start":28,"column_end":31,"is_primary":true,"text":[{"text":"        let grad = &diff * 2.0;","highlight_start":28,"highlight_end":31}],"label":"expected `&Tensor`, found floating-point number","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/loss/mod.rs:44:28\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m44\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        let grad = &diff * 2.0;\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found floating-point number\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/loss/mod.rs","byte_start":1310,"byte_end":1338,"line_start":47,"line_end":47,"column_start":43,"column_end":71,"is_primary":true,"text":[{"text":"            Reduction::Mean => Ok(&grad / (predictions.numel() as f32)),","highlight_start":43,"highlight_end":71}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/loss/mod.rs:47:43\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m47\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            Reduction::Mean => Ok(&grad / (predictions.numel() as f32)),\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/loss/mod.rs","byte_start":2754,"byte_end":2785,"line_start":95,"line_end":95,"column_start":43,"column_end":74,"is_primary":true,"text":[{"text":"            Reduction::Mean => Ok(&grad / (predictions.shape()[0] as f32)),","highlight_start":43,"highlight_end":74}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/loss/mod.rs:95:43\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m95\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            Reduction::Mean => Ok(&grad / (predictions.shape()[0] as f32)),\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/loss/mod.rs","byte_start":4589,"byte_end":4617,"line_start":153,"line_end":153,"column_start":43,"column_end":71,"is_primary":true,"text":[{"text":"            Reduction::Mean => Ok(&grad / (predictions.numel() as f32)),","highlight_start":43,"highlight_end":71}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/loss/mod.rs:153:43\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m153\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            Reduction::Mean => Ok(&grad / (predictions.numel() as f32)),\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/loss/mod.rs","byte_start":6363,"byte_end":6391,"line_start":216,"line_end":216,"column_start":43,"column_end":71,"is_primary":true,"text":[{"text":"            Reduction::Mean => Ok(&grad / (predictions.numel() as f32)),","highlight_start":43,"highlight_end":71}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/loss/mod.rs:216:43\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m216\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m            Reduction::Mean => Ok(&grad / (predictions.numel() as f32)),\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"`(dyn autograd::GradFunction + 'static)` doesn't implement `std::fmt::Debug`","code":{"code":"E0277","explanation":"You tried to use a type which doesn't implement some trait in a place which\nexpected that trait.\n\nErroneous code example:\n\n```compile_fail,E0277\n// here we declare the Foo trait with a bar method\ntrait Foo {\n    fn bar(&self);\n}\n\n// we now declare a function which takes an object implementing the Foo trait\nfn some_func<T: Foo>(foo: T) {\n    foo.bar();\n}\n\nfn main() {\n    // we now call the method with the i32 type, which doesn't implement\n    // the Foo trait\n    some_func(5i32); // error: the trait bound `i32 : Foo` is not satisfied\n}\n```\n\nIn order to fix this error, verify that the type you're using does implement\nthe trait. Example:\n\n```\ntrait Foo {\n    fn bar(&self);\n}\n\n// we implement the trait on the i32 type\nimpl Foo for i32 {\n    fn bar(&self) {}\n}\n\nfn some_func<T: Foo>(foo: T) {\n    foo.bar(); // we can now use this method since i32 implements the\n               // Foo trait\n}\n\nfn main() {\n    some_func(5i32); // ok!\n}\n```\n\nOr in a generic context, an erroneous code example would look like:\n\n```compile_fail,E0277\nfn some_func<T>(foo: T) {\n    println!(\"{:?}\", foo); // error: the trait `core::fmt::Debug` is not\n                           //        implemented for the type `T`\n}\n\nfn main() {\n    // We now call the method with the i32 type,\n    // which *does* implement the Debug trait.\n    some_func(5i32);\n}\n```\n\nNote that the error here is in the definition of the generic function. Although\nwe only call it with a parameter that does implement `Debug`, the compiler\nstill rejects the function. It must work with all possible input types. In\norder to make this example compile, we need to restrict the generic type we're\naccepting:\n\n```\nuse std::fmt;\n\n// Restrict the input type to types that implement Debug.\nfn some_func<T: fmt::Debug>(foo: T) {\n    println!(\"{:?}\", foo);\n}\n\nfn main() {\n    // Calling the method is still fine, as i32 implements Debug.\n    some_func(5i32);\n\n    // This would fail to compile now:\n    // struct WithoutDebug;\n    // some_func(WithoutDebug);\n}\n```\n\nRust only looks at the signature of the called function, as such it must\nalready specify all requirements that will be used for every type parameter.\n"},"level":"error","spans":[{"file_name":"src/autograd/mod.rs","byte_start":445,"byte_end":483,"line_start":16,"line_end":16,"column_start":5,"column_end":43,"is_primary":true,"text":[{"text":"    grad_fn: Option<Arc<dyn GradFunction>>,","highlight_start":5,"highlight_end":43}],"label":"`(dyn autograd::GradFunction + 'static)` cannot be formatted using `{:?}` because it doesn't implement `std::fmt::Debug`","suggested_replacement":null,"suggestion_applicability":null,"expansion":{"span":{"file_name":"src/autograd/mod.rs","byte_start":360,"byte_end":365,"line_start":12,"line_end":12,"column_start":10,"column_end":15,"is_primary":false,"text":[{"text":"#[derive(Debug, Clone)]","highlight_start":10,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null},"macro_decl_name":"#[derive(Debug)]","def_site_span":{"file_name":"/nix/store/8wybwvv517v5lg5hvg1l1ydfs97gd8hd-rust-mixed/lib/rustlib/src/rust/library/core/src/fmt/mod.rs","byte_start":32468,"byte_end":32483,"line_start":901,"line_end":901,"column_start":5,"column_end":20,"is_primary":false,"text":[{"text":"    pub macro Debug($item:item) {","highlight_start":5,"highlight_end":20}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}}}],"children":[{"message":"the trait `std::fmt::Debug` is not implemented for `(dyn autograd::GradFunction + 'static)`","code":null,"level":"help","spans":[],"children":[],"rendered":null},{"message":"the following other types implement trait `std::fmt::Debug`:\n  dyn std::any::Any + Send + Sync\n  dyn std::any::Any + Send\n  dyn std::any::Any\n  dyn tracing::Value","code":null,"level":"help","spans":[],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0277]\u001b[0m\u001b[0m\u001b[1m: `(dyn autograd::GradFunction + 'static)` doesn't implement `std::fmt::Debug`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/autograd/mod.rs:16:5\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m12\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m#[derive(Debug, Clone)]\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m          \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m-----\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12min this derive macro expansion\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m...\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m16\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    grad_fn: Option<Arc<dyn GradFunction>>,\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m     \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m`(dyn autograd::GradFunction + 'static)` cannot be formatted using `{:?}` because it doesn't implement `std::fmt::Debug`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mhelp\u001b[0m\u001b[0m: the trait `std::fmt::Debug` is not implemented for `(dyn autograd::GradFunction + 'static)`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mhelp\u001b[0m\u001b[0m: the following other types implement trait `std::fmt::Debug`:\u001b[0m\n\u001b[0m             dyn std::any::Any + Send + Sync\u001b[0m\n\u001b[0m             dyn std::any::Any + Send\u001b[0m\n\u001b[0m             dyn std::any::Any\u001b[0m\n\u001b[0m             dyn tracing::Value\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m= \u001b[0m\u001b[0m\u001b[1mnote\u001b[0m\u001b[0m: this error originates in the derive macro `Debug` (in Nightly builds, run with -Z macro-backtrace for more info)\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/transforms/mod.rs","byte_start":4096,"byte_end":4113,"line_start":124,"line_end":124,"column_start":28,"column_end":45,"is_primary":true,"text":[{"text":"        result = &result * brightness_factor;","highlight_start":28,"highlight_end":45}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/transforms/mod.rs:124:28\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m124\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        result = &result * brightness_factor;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                            \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/transforms/mod.rs","byte_start":4314,"byte_end":4318,"line_start":131,"line_end":131,"column_start":32,"column_end":36,"is_primary":true,"text":[{"text":"        result = &(&(&result - mean) * contrast_factor) + mean;","highlight_start":32,"highlight_end":36}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/transforms/mod.rs:131:32\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m131\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        result = &(&(&result - mean) * contrast_factor) + mean;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/transforms/mod.rs","byte_start":4322,"byte_end":4337,"line_start":131,"line_end":131,"column_start":40,"column_end":55,"is_primary":true,"text":[{"text":"        result = &(&(&result - mean) * contrast_factor) + mean;","highlight_start":40,"highlight_end":55}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/transforms/mod.rs:131:40\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m131\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        result = &(&(&result - mean) * contrast_factor) + mean;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                        \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/transforms/mod.rs","byte_start":4341,"byte_end":4345,"line_start":131,"line_end":131,"column_start":59,"column_end":63,"is_primary":true,"text":[{"text":"        result = &(&(&result - mean) * contrast_factor) + mean;","highlight_start":59,"highlight_end":63}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/transforms/mod.rs:131:59\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m131\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m        result = &(&(&result - mean) * contrast_factor) + mean;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"mismatched types","code":{"code":"E0308","explanation":"Expected type did not match the received type.\n\nErroneous code examples:\n\n```compile_fail,E0308\nfn plus_one(x: i32) -> i32 {\n    x + 1\n}\n\nplus_one(\"Not a number\");\n//       ^^^^^^^^^^^^^^ expected `i32`, found `&str`\n\nif \"Not a bool\" {\n// ^^^^^^^^^^^^ expected `bool`, found `&str`\n}\n\nlet x: f32 = \"Not a float\";\n//     ---   ^^^^^^^^^^^^^ expected `f32`, found `&str`\n//     |\n//     expected due to this\n```\n\nThis error occurs when an expression was used in a place where the compiler\nexpected an expression of a different type. It can occur in several cases, the\nmost common being when calling a function and passing an argument which has a\ndifferent type than the matching type in the function declaration.\n"},"level":"error","spans":[{"file_name":"src/utils/mod.rs","byte_start":3737,"byte_end":3746,"line_start":140,"line_end":140,"column_start":43,"column_end":52,"is_primary":true,"text":[{"text":"                let clipped_grad = grad * clip_coef;","highlight_start":43,"highlight_end":52}],"label":"expected `&Tensor`, found `f32`","suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror[E0308]\u001b[0m\u001b[0m\u001b[1m: mismatched types\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m--> \u001b[0m\u001b[0msrc/utils/mod.rs:140:43\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;12m140\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m                let clipped_grad = grad * clip_coef;\u001b[0m\n\u001b[0m    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;12m|\u001b[0m\u001b[0m                                           \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9m^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;9mexpected `&Tensor`, found `f32`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"aborting due to 81 previous errors; 16 warnings emitted","code":null,"level":"error","spans":[],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;9merror\u001b[0m\u001b[0m\u001b[1m: aborting due to 81 previous errors; 16 warnings emitted\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"Some errors have detailed explanations: E0034, E0275, E0277, E0308, E0369, E0432, E0599.","code":null,"level":"failure-note","spans":[],"children":[],"rendered":"\u001b[0m\u001b[1mSome errors have detailed explanations: E0034, E0275, E0277, E0308, E0369, E0432, E0599.\u001b[0m\n"}
{"$message_type":"diagnostic","message":"For more information about an error, try `rustc --explain E0034`.","code":null,"level":"failure-note","spans":[],"children":[],"rendered":"\u001b[0m\u001b[1mFor more information about an error, try `rustc --explain E0034`.\u001b[0m\n"}
