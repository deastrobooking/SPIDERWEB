#!/usr/bin/env python3
"""
ML-as-a-Service Platform Demo Server

A comprehensive REST API server for AI-enhanced machine learning model development,
orchestrating five major AI providers (OpenAI, Anthropic, Perplexity, Gemini, Grok).

Features:
    - Multi-provider AI service orchestration
    - Synthetic training data generation
    - Advanced model analysis and optimization
    - Real-time research integration
    - Interactive web dashboard for testing

Environment Variables:
    OPENAI_API_KEY: OpenAI API key for GPT-4 integration
    ANTHROPIC_API_KEY: Anthropic API key for Claude integration
    PERPLEXITY_API_KEY: Perplexity API key for research integration (optional)
    GEMINI_API_KEY: Google Gemini API key for multimodal analysis (optional)
    XAI_API_KEY: xAI Grok API key for creative problem-solving (optional)

Usage:
    python3 demo_server.py

    Server runs on http://0.0.0.0:5000
    Dashboard available at http://localhost:5000

API Endpoints:
    GET  /health                  - Health check endpoint
    GET  /v1/ai/status           - AI service configuration status
    POST /v1/ai/enhance          - Comprehensive model enhancement
    POST /v1/ai/synthetic-data   - Generate synthetic training data
    POST /v1/ai/analyze          - Advanced model analysis
"""

import os
import uuid
import json
from datetime import datetime
import time

# Check if OpenAI is available
try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Check if Anthropic is available  
try:
    import anthropic
    from anthropic import Anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

app = Flask(__name__)
# Enable CORS for all origins, useful for local development and testing
# In production, restrict origins to your frontend domain(s)
CORS(app) 

@app.route('/')
def index():
    """Main dashboard for ML-as-a-Service Platform"""
    return '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML-as-a-Service Platform</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #0f0f0f; color: #fff; }
        .container { max-width: 1200px; margin: 0 auto; padding: 20px; }
        .header { text-align: center; margin-bottom: 40px; }
        .header h1 { font-size: 2.5rem; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; margin-bottom: 10px; }
        .header p { font-size: 1.2rem; color: #ccc; }
        .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin-bottom: 40px; }
        .card { background: linear-gradient(135deg, #1e1e1e 0%, #2d2d2d 100%); border-radius: 12px; padding: 24px; border: 1px solid #333; }
        .card h3 { color: #667eea; margin-bottom: 16px; font-size: 1.3rem; }
        .card p { color: #ccc; margin-bottom: 16px; line-height: 1.6; }
        .status { padding: 8px 16px; border-radius: 20px; font-size: 0.9rem; font-weight: 500; }
        .status.configured { background: #065f46; color: #10b981; }
        .status.not-configured { background: #7f1d1d; color: #f87171; }
        .button { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 12px 24px; border: none; border-radius: 8px; cursor: pointer; font-size: 1rem; text-decoration: none; display: inline-block; margin-top: 12px; }
        .button:hover { transform: translateY(-2px); box-shadow: 0 8px 25px rgba(102, 126, 234, 0.3); }
        .api-section { background: #1a1a1a; border-radius: 12px; padding: 24px; margin-top: 40px; }
        .api-section h2 { color: #667eea; margin-bottom: 20px; }
        .endpoint { background: #2d2d2d; border-radius: 8px; padding: 16px; margin-bottom: 12px; border-left: 4px solid #667eea; }
        .endpoint code { color: #10b981; font-family: 'Monaco', 'Menlo', monospace; }
        .endpoint .method { background: #065f46; color: #10b981; padding: 4px 8px; border-radius: 4px; font-size: 0.8rem; margin-right: 8px; }
        .method.post { background: #7c2d12; color: #fb923c; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ML-as-a-Service Platform</h1>
            <p>Comprehensive AI-Enhanced Machine Learning Development Platform</p>
        </div>

        <div class="grid">
            <div class="card">
                <h3>AI Service Integration</h3>
                <p>Multi-provider AI orchestration with OpenAI, Anthropic, Perplexity, Gemini, and Grok for enhanced model development.</p>
                <div id="service-status">Loading service status...</div>
                <a href="/v1/ai/status" class="button">Check AI Services</a>
            </div>

            <div class="card">
                <h3>Model Enhancement</h3>
                <p>Comprehensive model optimization using advanced AI reasoning, synthetic data generation, and real-time research integration.</p>
                <a href="#enhance" class="button" onclick="testEnhancement()">Test Enhancement</a>
            </div>

            <div class="card">
                <h3>Synthetic Data Generation</h3>
                <p>Generate high-quality training data using OpenAI's advanced language models for improved model performance.</p>
                <a href="#synthetic" class="button" onclick="testSynthetic()">Generate Data</a>
            </div>

            <div class="card">
                <h3>Advanced Analysis</h3>
                <p>Deep model analysis and reasoning using Anthropic's Claude for interpretability and optimization insights.</p>
                <a href="#analyze" class="button" onclick="testAnalysis()">Analyze Model</a>
            </div>
        </div>

        <div class="api-section">
            <h2>API Endpoints</h2>
            <div class="endpoint">
                <span class="method">GET</span>
                <code>/v1/ai/status</code> - Check AI service configuration and capabilities
            </div>
            <div class="endpoint">
                <span class="method post">POST</span>
                <code>/v1/ai/enhance</code> - Comprehensive multi-provider model enhancement
            </div>
            <div class="endpoint">
                <span class="method post">POST</span>
                <code>/v1/ai/synthetic-data</code> - Generate synthetic training data
            </div>
            <div class="endpoint">
                <span class="method post">POST</span>
                <code>/v1/ai/analyze</code> - Advanced model analysis and reasoning
            </div>
        </div>
    </div>

    <script>
        async function loadServiceStatus() {
            try {
                const response = await fetch('/v1/ai/status');
                const data = await response.json();
                const statusDiv = document.getElementById('service-status');

                let configuredServices = 0;
                let totalServices = 0;

                Object.values(data.services).forEach(service => {
                    if (service.configured !== undefined) {
                        totalServices++;
                        if (service.configured) configuredServices++;
                    }
                });

                statusDiv.innerHTML = `
                    <div style="margin-top: 12px;">
                        <div class="status ${data.status === 'operational' ? 'configured' : 'not-configured'}">
                            ${configuredServices}/${totalServices} AI Services Configured
                        </div>
                    </div>
                `;
            } catch (error) {
                document.getElementById('service-status').innerHTML = '<div class="status not-configured">Error loading status</div>';
            }
        }

        async function testEnhancement() {
            const payload = {
                model_description: "Image classification model for autonomous vehicles",
                training_data_sample: ["highway_scene_1.jpg", "urban_intersection_2.jpg", "night_driving_3.jpg"],
                performance_metrics: { accuracy: 0.94, precision: 0.91, recall: 0.89 },
                enhancement_config: { generate_synthetic_data: true, optimize_training_strategy: true }
            };

            try {
                const response = await fetch('/v1/ai/enhance', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                const result = await response.json();
                alert('Enhancement completed! Check browser console for details.');
                console.log('Enhancement Result:', result);
            } catch (error) {
                alert('Enhancement test failed: ' + error.message);
            }
        }

        async function testSynthetic() {
            const payload = {
                model_description: "Natural language processing model for customer sentiment analysis",
                existing_data_sample: ["Great product, highly recommend!", "Poor quality, disappointed", "Average experience"],
                target_count: 10
            };

            try {
                const response = await fetch('/v1/ai/synthetic-data', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                const result = await response.json();
                alert('Synthetic data generated! Check browser console for details.');
                console.log('Synthetic Data:', result);
            } catch (error) {
                alert('Synthetic data generation failed: ' + error.message);
            }
        }

        async function testAnalysis() {
            const payload = {
                model_description: "Deep learning model for medical image diagnosis",
                training_data_sample: ["chest_xray_1.jpg", "chest_xray_2.jpg", "chest_xray_3.jpg"],
                performance_metrics: { sensitivity: 0.92, specificity: 0.88, auc_roc: 0.94 }
            };

            try {
                const response = await fetch('/v1/ai/analyze', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                const result = await response.json();
                alert('Analysis completed! Check browser console for details.');
                console.log('Analysis Result:', result);
            } catch (error) {
                alert('Analysis test failed: ' + error.message);
            }
        }

        loadServiceStatus();
    </script>
</body>
</html>
    '''

class AIServiceOrchestrator:
    """
    Orchestrates multiple AI service providers for machine learning tasks.

    This class manages integrations with OpenAI, Anthropic, Perplexity, Gemini, and Grok,
    facilitating advanced model enhancement, synthetic data generation, and analysis.
    """
    def __init__(self):
        """Initializes the AI service orchestrator."""
        self.openai_client = None
        self.anthropic_client = None
        self.perplexity_configured = False
        self.gemini_configured = False
        self.grok_configured = False

        # Initialize OpenAI if available and configured
        if OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY'):
            try:
                self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
                print("âœ… OpenAI client initialized.")
            except Exception as e:
                print(f"âŒ OpenAI client initialization failed: {e}")

        # Initialize Anthropic if available and configured
        if ANTHROPIC_AVAILABLE and os.getenv('ANTHROPIC_API_KEY'):
            try:
                self.anthropic_client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
                print("âœ… Anthropic client initialized.")
            except Exception as e:
                print(f"âŒ Anthropic client initialization failed: {e}")

        # Check other service configurations from environment variables
        self.perplexity_configured = bool(os.getenv('PERPLEXITY_API_KEY'))
        if self.perplexity_configured: print("âœ… Perplexity configured.")
        self.gemini_configured = bool(os.getenv('GEMINI_API_KEY'))
        if self.gemini_configured: print("âœ… Gemini configured.")
        self.grok_configured = bool(os.getenv('XAI_API_KEY')) # Assuming XAI_API_KEY for Grok
        if self.grok_configured: print("âœ… Grok configured.")

    def get_service_status(self):
        """
        Retrieves the current status and configuration of all integrated AI services.

        Returns:
            dict: A dictionary containing the overall status and details for each service.
        """
        any_configured = (self.openai_client is not None or self.anthropic_client is not None or 
                         self.perplexity_configured or self.gemini_configured or self.grok_configured)

        return {
            "status": "operational" if any_configured else "requires_configuration",
            "services": {
                "openai_service": {
                    "configured": self.openai_client is not None,
                    "available": OPENAI_AVAILABLE,
                    "capabilities": ["synthetic_data", "knowledge_extraction", "embeddings", "optimization"]
                },
                "anthropic_service": {
                    "configured": self.anthropic_client is not None,
                    "available": ANTHROPIC_AVAILABLE,
                    "capabilities": ["reasoning", "interpretability", "strategy_generation", "debugging"]
                },
                "perplexity_service": {
                    "configured": self.perplexity_configured,
                    "available": True, # Assumed available if API key is set
                    "capabilities": ["search_enhanced_training", "industry_benchmarks", "competitive_analysis", "research_backed_augmentation"]
                },
                "gemini_service": {
                    "configured": self.gemini_configured,
                    "available": True, # Assumed available if API key is set
                    "capabilities": ["multimodal_analysis", "code_optimization", "testing_strategies", "deployment_planning"]
                },
                "grok_service": {
                    "configured": self.grok_configured,
                    "available": True, # Assumed available if API key is set
                    "capabilities": ["innovative_architecture", "creative_problem_solving", "experimental_training", "breakthrough_evaluation"]
                },
                "orchestrator": {
                    "available": True,
                    "features": ["multi_provider_enhancement", "knowledge_distillation", "comprehensive_analysis", "innovative_solutions"]
                }
            },
            "message": "AI services ready for model enhancement" if any_configured 
                      else "Configure API keys: OPENAI_API_KEY, ANTHROPIC_API_KEY, PERPLEXITY_API_KEY, GEMINI_API_KEY, XAI_API_KEY"
        }

    async def generate_synthetic_data(self, model_description: str, existing_data: list, target_count: int) -> dict:
        """
        Generates synthetic training data using OpenAI's GPT-4o model.

        Args:
            model_description (str): A description of the ML model for which to generate data.
            existing_data (list): A sample of existing data to guide generation.
            target_count (int): The desired number of synthetic data examples.

        Returns:
            dict: A dictionary containing the generated synthetic data or an error message.
        """
        if not self.openai_client:
            return {
                "error": "OpenAI not configured or API key missing.",
                "synthetic_data": [f"Demo synthetic example {i+1} for {model_description}" for i in range(min(target_count, 5))],
                "note": "Set OPENAI_API_KEY environment variable for real AI-generated data."
            }

        try:
            # Use the latest available OpenAI model for best results
            response = self.openai_client.chat.completions.create(
                model="gpt-4o", # Latest model as of May 2024
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert synthetic data generator. Your task is to create diverse, high-quality, and representative training examples based on the provided context. Ensure variety in format and content where appropriate."
                    },
                    {
                        "role": "user", 
                        "content": f"Generate {target_count} diverse and realistic training examples for a model described as: '{model_description}'. "
                                  f"These examples should be inspired by the following existing data samples: {existing_data[:3]}. "
                                  f"Please format each example clearly, and return them as a list, with each example on a new line."
                    }
                ],
                max_tokens=2000,
                temperature=0.8 # A balance between creativity and predictability
            )

            content = response.choices[0].message.content
            # Process the response to extract individual data points
            synthetic_data = [line.strip() for line in content.split('\n') if line.strip()]

            return {
                "synthetic_data": synthetic_data[:target_count], # Ensure we return only the requested count
                "generation_method": "openai_gpt4o",
                "source_model": "gpt-4o"
            }

        except Exception as e:
            print(f"Error during OpenAI synthetic data generation: {e}")
            return {
                "error": f"OpenAI generation failed: {str(e)}",
                "synthetic_data": [f"Fallback example {i+1}" for i in range(min(target_count, 3))],
                "note": "Please check your OpenAI API key, organization settings, and available quota."
            }

    async def analyze_model_reasoning(self, model_description: str, data_sample: list, performance_metrics: dict) -> dict:
        """
        Performs advanced model analysis and reasoning using Anthropic's Claude 3.5 Sonnet.

        Args:
            model_description (str): Description of the ML model.
            data_sample (list): A sample of the training data used.
            performance_metrics (dict): Key performance metrics of the model.

        Returns:
            dict: Analysis results, including reasoning and recommendations, or an error message.
        """
        if not self.anthropic_client:
            return {
                "error": "Anthropic not configured or API key missing.", 
                "reasoning": f"Demo reasoning analysis for model: {model_description}. Provide ANTHROPIC_API_KEY for real analysis.",
                "note": "Set ANTHROPIC_API_KEY environment variable for actual reasoning analysis."
            }

        try:
            # Use the latest available Anthropic model for best results
            message = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022", # Latest model as of October 2024
                max_tokens=2000,
                messages=[
                    {
                        "role": "user",
                        "content": f"You are an expert AI consultant specializing in ML model optimization. Analyze the following ML model and provide actionable insights:\n\n"
                                  f"**Model Description:**\n{model_description}\n\n"
                                  f"**Training Data Sample (first 3 entries):**\n{data_sample[:3]}\n\n"
                                  f"**Performance Metrics:**\n{json.dumps(performance_metrics, indent=2)}\n\n"
                                  f"Provide specific, detailed recommendations for the following areas:\n"
                                  f"1. **Architecture Improvements:** Suggest alternative architectures or modifications.\n"
                                  f"2. **Training Strategy Optimization:** Recommend adjustments to hyperparameters, data augmentation, or training procedures.\n"
                                  f"3. **Potential Bottlenecks:** Identify areas that might limit performance or scalability.\n"
                                  f"4. **Risk Mitigation Approaches:** Advise on reducing bias, improving robustness, or enhancing interpretability."
                    }
                ]
            )

            reasoning = message.content[0].text

            return {
                "reasoning_analysis": reasoning,
                "analysis_method": "anthropic_claude35_sonnet",
                "source_model": "claude-3-5-sonnet-20241022"
            }

        except Exception as e:
            print(f"Error during Anthropic model analysis: {e}")
            return {
                "error": f"Anthropic analysis failed: {str(e)}",
                "reasoning": "Demo reasoning analysis completed. Please check your Anthropic API key and quota.",
                "note": "Check Anthropic API key and quota."
            }

    async def comprehensive_enhancement(self, model_description: str, training_data: list, performance_metrics: dict, config: dict) -> dict:
        """
        Executes a full model enhancement pipeline by orchestrating multiple AI services.

        Args:
            model_description (str): Description of the ML model.
            training_data (list): Sample of training data.
            performance_metrics (dict): Model performance metrics.
            config (dict): Configuration options for the enhancement process.

        Returns:
            dict: A detailed report of the enhancement process, including results from various AI services.
        """
        enhancement_report = {
            "job_id": str(uuid.uuid4()),
            "created_at": datetime.utcnow().isoformat() + "Z", # ISO 8601 format with Zulu time
            "enhancement_version": "2.1.0", # Incremented version
            "input_parameters": {
                "model_description": model_description,
                "performance_metrics": performance_metrics,
                "enhancement_config": config
            }
        }

        # --- Step 1: Synthetic Data Generation ---
        if config.get("generate_synthetic_data", True):
            synthetic_result = await self.generate_synthetic_data(
                model_description, 
                training_data, 
                config.get("synthetic_data_count", 20) # Default to 20 if not specified
            )
            enhancement_report["synthetic_data_generation"] = synthetic_result
        else:
             enhancement_report["synthetic_data_generation"] = {"status": "skipped"}

        # --- Step 2: Reasoning and Strategy Analysis ---
        if config.get("optimize_training_strategy", True):
            reasoning_result = await self.analyze_model_reasoning(
                model_description,
                training_data,
                performance_metrics
            )
            enhancement_report["training_strategy_analysis"] = reasoning_result
        else:
             enhancement_report["training_strategy_analysis"] = {"status": "skipped"}

        # --- Step 3: Perplexity Search-Enhanced Recommendations ---
        if self.perplexity_configured:
            enhancement_report["search_enhanced_training"] = {
                "service": "perplexity",
                "status": "configured",
                "capabilities": ["real_time_research_integration", "industry_benchmarks", "competitive_analysis", "research_backed_augmentation"],
                "note": "Leveraging Perplexity for up-to-date research and benchmarks."
            }
        else:
            enhancement_report["search_enhanced_training"] = {
                "service": "perplexity",
                "status": "not_configured",
                "demo_capability": "Simulated search-enhanced training with real-time research integration.",
                "note": "Set PERPLEXITY_API_KEY to enable real-time industry insights and research."
            }

        # --- Step 4: Gemini Multimodal Analysis ---
        if self.gemini_configured:
            enhancement_report["multimodal_analysis"] = {
                "service": "gemini",
                "status": "configured",
                "capabilities": ["multimodal_analysis", "code_optimization", "testing_strategies", "deployment_planning"],
                "note": "Utilizing Gemini for advanced multimodal analysis and optimization planning."
            }
        else:
            enhancement_report["multimodal_analysis"] = {
                "service": "gemini", 
                "status": "not_configured",
                "demo_capability": "Simulated multimodal analysis, code optimization, and deployment strategies.",
                "note": "Set GEMINI_API_KEY to access Google's multimodal AI capabilities."
            }

        # --- Step 5: Grok Innovative Solutions ---
        if self.grok_configured:
            enhancement_report["innovative_solutions"] = {
                "service": "grok",
                "status": "configured",
                "capabilities": ["innovative_architecture", "creative_problem_solving", "experimental_training", "breakthrough_evaluation"],
                "note": "Leveraging Grok for cutting-edge architecture and creative problem-solving."
            }
        else:
            enhancement_report["innovative_solutions"] = {
                "service": "grok",
                "status": "not_configured", 
                "demo_capability": "Simulated innovative architecture design and creative problem-solving approaches.",
                "note": "Set XAI_API_KEY for xAI's advanced innovation capabilities."
            }

        # --- Step 6: Enhanced Knowledge Distillation Guidance ---
        # Determine which services are actually configured and available
        configured_services_list = []
        if self.openai_client: configured_services_list.append("openai")
        if self.anthropic_client: configured_services_list.append("anthropic")
        if self.perplexity_configured: configured_services_list.append("perplexity")
        if self.gemini_configured: configured_services_list.append("gemini")
        if self.grok_configured: configured_services_list.append("grok")

        if config.get("enable_distillation", True):
            enhancement_report["distillation_guidance"] = {
                "method": "multi_provider_ai_enhanced_distillation",
                "teacher_services_used": configured_services_list if configured_services_list else ["demo_fallback"],
                "distillation_temperature": config.get("distillation_temperature", 3.0),
                "knowledge_transfer_rate": config.get("knowledge_transfer_rate", 0.8),
                "innovation_factor": config.get("innovation_factor", 0.9 if self.grok_configured else 0.7), # Higher if Grok is available
                "search_enhancement_applied": self.perplexity_configured,
                "multimodal_integration_applied": self.gemini_configured,
                "note": "Guidance for distilling knowledge from multiple AI teachers into a student model."
            }
        else:
            enhancement_report["distillation_guidance"] = {"status": "skipped"}

        # --- Step 7: Orchestration Summary ---
        total_potential_services = 5
        num_configured_services = len(configured_services_list)

        enhancement_report["orchestration_summary"] = {
            "total_potential_services": total_potential_services,
            "configured_services_count": num_configured_services,
            "service_utilization": {
                "generative_ai_used": bool(self.openai_client),
                "reasoning_ai_used": bool(self.anthropic_client), 
                "search_enhanced_ai_used": self.perplexity_configured,
                "multimodal_ai_used": self.gemini_configured,
                "innovative_ai_used": self.grok_configured
            },
            "enhancement_completeness_score": round(num_configured_services / total_potential_services, 2) if total_potential_services > 0 else 0,
            "message": f"Comprehensive enhancement completed using {num_configured_services} of {total_potential_services} available AI services."
        }

        return enhancement_report

# Initialize the orchestrator globally
orchestrator = AIServiceOrchestrator()

@app.route('/health')
def health_check():
    """
    Health check endpoint for the ML-as-a-Service Platform.
    Indicates the overall status and available features of the server.
    """
    return jsonify({
        "status": "healthy",
        "service": "ML-as-a-Service Platform Demo",
        "version": "1.1.0", # Updated version
        "features": [
            "external_ai_integration",
            "multi_provider_orchestration",
            "model_enhancement_pipeline",
            "synthetic_data_generation",
            "advanced_model_analysis",
            "web_dashboard"
        ],
        "timestamp": datetime.utcnow().isoformat() + "Z"
    })

@app.route('/v1/ai/status')
def get_ai_service_status():
    """
    API endpoint to retrieve the status and configuration of all integrated AI services.
    """
    return jsonify(orchestrator.get_service_status())

@app.route('/v1/ai/synthetic-data', methods=['POST'])
def generate_synthetic_data_api():
    """
    API endpoint to trigger synthetic data generation using an AI service.
    Expects a JSON payload with model description, existing data samples, and target count.
    """
    data = request.get_json()

    if not data:
        return jsonify({"error": "Request must be JSON"}), 400

    model_description = data.get('model_description', '')
    # Renamed parameter to match frontend function call
    existing_data = data.get('existing_data_sample', []) 
    target_count = data.get('target_count', 10)

    if not model_description:
        return jsonify({"error": "model_description is required"}), 400
    if target_count <= 0:
         return jsonify({"error": "target_count must be a positive integer"}), 400

    job_id = str(uuid.uuid4())

    # Simulate async operation using asyncio.run for simplicity in this context
    # In a production Flask app, consider using Flask-Executor or other async handling
    import asyncio
    try:
        result = asyncio.run(orchestrator.generate_synthetic_data(
            model_description, existing_data, target_count
        ))
    except Exception as e:
        # Catch potential issues with asyncio.run or orchestrator itself
        return jsonify({
            "job_id": job_id,
            "error": f"An unexpected error occurred during processing: {str(e)}",
            "status": "failed"
        }), 500

    return jsonify({
        "job_id": job_id,
        "status": "completed" if "error" not in result else "failed",
        "generated_count": len(result.get("synthetic_data", [])),
        "synthetic_data": result.get("synthetic_data", []),
        "generation_metadata": {
            "generation_method": result.get("generation_method", "demo_fallback"),
            "source_services": ["openai"] if orchestrator.openai_client else ["demo_fallback"],
            "original_sample_size": len(existing_data),
            "target_count": target_count
        },
        "error": result.get("error"),
        "note": result.get("note")
    })

@app.route('/v1/ai/analyze', methods=['POST'])
def analyze_model_api():
    """
    API endpoint to trigger model analysis using an AI service.
    Expects a JSON payload with model description, training data sample, and performance metrics.
    """
    data = request.get_json()

    if not data:
        return jsonify({"error": "Request must be JSON"}), 400

    model_description = data.get('model_description', '')
    # Ensure parameters match frontend calls and are consistently named
    training_data = data.get('training_data_sample', []) 
    performance_metrics = data.get('performance_metrics', {})
    analysis_type = data.get('analysis_type', 'reasoning') # Keep analysis_type for potential future use

    if not model_description:
        return jsonify({"error": "model_description is required"}), 400
    if not performance_metrics:
        return jsonify({"error": "performance_metrics are required"}), 400

    analysis_id = str(uuid.uuid4())

    import asyncio
    try:
        result = asyncio.run(orchestrator.analyze_model_reasoning(
            model_description, training_data, performance_metrics
        ))
    except Exception as e:
        return jsonify({
            "analysis_id": analysis_id,
            "error": f"An unexpected error occurred during analysis: {str(e)}",
            "status": "failed"
        }), 500

    recommendations = []
    # Generate basic recommendations if analysis was successful
    if 'reasoning_analysis' in result and not result.get('error'):
        recommendations = [
            "Carefully review the detailed AI-driven recommendations provided.",
            "Prioritize changes based on potential impact and feasibility.",
            "Consider A/B testing any significant architectural or strategy modifications.",
            "Monitor key metrics closely after implementing suggested changes."
        ]

    return jsonify({
        "analysis_id": analysis_id,
        "analysis_type": analysis_type,
        "status": "completed" if 'reasoning_analysis' in result and not result.get('error') else "failed",
        "analysis_results": result,
        "generated_recommendations": recommendations
    })

@app.route('/v1/ai/enhance', methods=['POST'])
def enhance_model_api():
    """
    API endpoint for comprehensive model enhancement.
    Orchestrates multiple AI services based on the provided configuration.
    Expects a JSON payload with model description, training data, performance metrics, and enhancement config.
    """
    data = request.get_json()

    if not data:
        return jsonify({"error": "Request must be JSON"}), 400

    model_description = data.get('model_description', '')
    training_data = data.get('training_data_sample', [])
    performance_metrics = data.get('performance_metrics', {})
    enhancement_config = data.get('enhancement_config', {}) # User-defined configuration for enhancement

    # Basic validation
    if not model_description:
        return jsonify({"error": "model_description is required"}), 400
    if not performance_metrics:
        return jsonify({"error": "performance_metrics are required"}), 400

    job_id = str(uuid.uuid4())

    import asyncio
    try:
        enhancement_report = asyncio.run(orchestrator.comprehensive_enhancement(
            model_description, training_data, performance_metrics, enhancement_config
        ))
        enhancement_report["job_id"] = job_id # Ensure job_id is part of the report
        status = "completed"
    except Exception as e:
        # Handle potential errors during the complex orchestration
        enhancement_report = {
            "job_id": job_id,
            "error": f"An unexpected error occurred during model enhancement: {str(e)}",
            "status": "failed"
        }
        status = "failed"
        print(f"Error during comprehensive enhancement: {e}")

    return jsonify({
        "job_id": job_id,
        "status": status,
        "enhancement_report": enhancement_report,
        "message": "Model enhancement process initiated and results compiled." if status == "completed" else "Model enhancement process failed."
    })

# --- Additional Demo Endpoints ---

@app.route('/v1/models')
def list_models():
    """
    Demo endpoint to list available AI-enhanced models.
    """
    return jsonify({
        "models": [
            {
                "id": "model-001",
                "name": "ai_enhanced_classifier_v1.1", # Updated model name
                "framework": "pytorch",
                "status": "active",
                "ai_enhanced": True,
                "created_at": "2025-06-20T10:00:00Z"
            }
        ],
        "total_count": 1,
        "retrieved_count": 1
    })

@app.route('/v1/train', methods=['POST'])
def start_training():
    """
    Demo endpoint to simulate starting a model training job.
    Indicates if AI enhancement is enabled for the training.
    """
    data = request.get_json() # Potentially get training parameters
    ai_enhancement_enabled = data.get('enable_ai_enhancement', True) if data else True

    return jsonify({
        "job_id": str(uuid.uuid4()),
        "status": "queued",
        "message": "Training job initiated.",
        "ai_enhancement_applied": ai_enhancement_enabled,
        "details": "AI enhancement features will be utilized if configured and enabled."
    })

# --- Main Execution Block ---
if __name__ == '__main__':
    print("ðŸš€ ML-as-a-Service Platform Demo Server")
    print("=" * 50)

    # Check API configuration and print status
    openai_configured = bool(os.getenv('OPENAI_API_KEY'))
    anthropic_configured = bool(os.getenv('ANTHROPIC_API_KEY'))
    perplexity_configured = bool(os.getenv('PERPLEXITY_API_KEY'))
    gemini_configured = bool(os.getenv('GEMINI_API_KEY'))
    grok_configured = bool(os.getenv('XAI_API_KEY'))

    print(f"OpenAI Integration: {'âœ… Configured' if openai_configured else 'âŒ Not configured'}")
    print(f"Anthropic Integration: {'âœ… Configured' if anthropic_configured else 'âŒ Not configured'}")
    print(f"Perplexity Integration: {'âœ… Configured' if perplexity_configured else 'âŒ Not configured'}")
    print(f"Gemini Integration: {'âœ… Configured' if gemini_configured else 'âŒ Not configured'}")
    print(f"Grok Integration: {'âœ… Configured' if grok_configured else 'âŒ Not configured'}")

    # Provide guidance if core services are missing
    if not openai_configured or not anthropic_configured:
        print("\nðŸ’¡ To enable core AI functionality (data generation & analysis):")
        print("   export OPENAI_API_KEY='your_openai_key'")
        print("   export ANTHROPIC_API_KEY='your_anthropic_key'")
    
    if not perplexity_configured or not gemini_configured or not grok_configured:
         print("\nðŸ’¡ To enable advanced AI integrations (research, multimodal, innovation):")
         print("   export PERPLEXITY_API_KEY='your_perplexity_key'")
         print("   export GEMINI_API_KEY='your_gemini_key'")
         print("   export XAI_API_KEY='your_xai_grok_key'")

    print(f"\nðŸŒ Server starting on http://0.0.0.0:5000")
    print("   Dashboard available at http://localhost:5000")
    print("\nðŸ“¡ AI Enhancement API Endpoints:")
    print("   GET  /health                  - Server health check")
    print("   GET  /v1/ai/status           - Get status of all integrated AI services")
    print("   POST /v1/ai/enhance          - Trigger comprehensive model enhancement pipeline")
    print("   POST /v1/ai/synthetic-data   - Generate synthetic training data") 
    print("   POST /v1/ai/analyze          - Perform advanced model analysis and reasoning")
    print("   GET  /v1/models              - List available demo models")
    print("   POST /v1/train              - Simulate model training job start")

    # Start the Flask development server
    # debug=True enables auto-reloading and detailed error pages, suitable for development
    # In production, use a proper WSGI server like Gunicorn or uWSGI
    app.run(host='0.0.0.0', port=5000, debug=True)